{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import io\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Input,concatenate, merge, Dense, Dropout, Activation, RepeatVector, Permute, Reshape, RepeatVector, Flatten\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import  GRU\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import log_loss, classification_report,accuracy_score,f1_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    # to store the vocabulary\n",
    "    def __init__(self):\n",
    "        self.word2idx = {'<pad>': 0, '<unk>': 1}\n",
    "        self.idx2word = ['<pad>', '<unk>']\n",
    "        self.tag2idx = {'<pad>': 0, '<unk>': 1}\n",
    "        self.idx2tag = ['<pad>', '<unk>'] \n",
    "        self.word_vocab_size = 2 \n",
    "        self.tag_vocab_size  = 2\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1\n",
    "            self.word_vocab_size+=1\n",
    "        return self.word2idx[word]\n",
    "    \n",
    "    def add_tag(self, tag):\n",
    "        if tag not in self.tag2idx:\n",
    "            self.idx2tag.append(tag)\n",
    "            self.tag2idx[tag] = len(self.idx2tag) - 1\n",
    "            self.tag_vocab_size+=1\n",
    "        return self.tag2idx[tag]   \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "\n",
    "\n",
    "class SlotDataset(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.utterances = []\n",
    "        self.tags =[]\n",
    "        self.padded_utterances = []\n",
    "        self.padded_tags =[]\n",
    "        self.one_hot_tags =[]\n",
    "        \n",
    "    def add_utterance(self, utt):\n",
    "        self.utterances.append(utt)\n",
    "        \n",
    "    def add_slots(self, slots):\n",
    "        self.tags.append(slots)\n",
    "        \n",
    "    def pad_utts(self,time_length=100):\n",
    "        self.padded_utterances = sequence.pad_sequences(self.utterances, maxlen=time_length, dtype='int32', padding='pre')\n",
    "        return self.padded_utterances\n",
    "    \n",
    "    def pad_tags(self,time_length=100):\n",
    "        self.padded_tags = sequence.pad_sequences(self.tags, maxlen=time_length, dtype='int32', padding='pre')\n",
    "        return self.padded_tags\n",
    "    \n",
    "    def get_one_hot_tags(self,tag_vocab_size=100):\n",
    "        self.one_hot_tags =[]\n",
    "        for i,sentence  in  enumerate(self.padded_tags):\n",
    "            temp_sent = self.convert_to_one_hot(sentence,tag_vocab_size)\n",
    "            self.one_hot_tags.append(temp_sent)\n",
    "        self.one_hot_tags = np.array(self.one_hot_tags)\n",
    "        return self.one_hot_tags\n",
    "    \n",
    "    def convert_to_one_hot(self,Y, C):\n",
    "        Y = np.eye(C)[Y.reshape(-1)]\n",
    "        return Y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "\n",
    "\n",
    "class Corpus(object):\n",
    "    \n",
    "    def __init__(self, data_dir='data',embeddings_file=\"glove.6B.50d.txt\", train_file=\"atis-2.train.w-intent.iob\", valid_file=\"atis-2.dev.w-intent.iob\" ,test_file=\"atis.test.w-intent.iob\",):\n",
    "        self.train = SlotDataset()\n",
    "        self.valid = SlotDataset()\n",
    "        self.test = SlotDataset()\n",
    "        \n",
    "        self.dictionary = Dictionary()\n",
    "        #self.embeddings = GolveEmbbedings(os.path.join(data_dir, embeddings_file))\n",
    "        self.load_train(os.path.join(data_dir, train_file))\n",
    "        self.load_valid(os.path.join(data_dir, valid_file))\n",
    "        self.load_test(os.path.join(data_dir, test_file))\n",
    "        \n",
    "    def load_train(self, path):\n",
    "        for line in open(path, 'r'):\n",
    "            words=line.split('\\t')[0].strip().split()\n",
    "            tags=line.split('\\t')[1].strip().split()\n",
    "            temp_utt = list()\n",
    "            temp_tags = list()\n",
    "            for i in range(len(words)):\n",
    "                id_word = self.dictionary.add_word(words[i])\n",
    "                id_tag  = self.dictionary.add_tag(tags[i])\n",
    "                temp_utt.append(id_word)\n",
    "                temp_tags.append(id_tag)\n",
    "            self.train.add_utterance(np.array(temp_utt))\n",
    "            self.train.add_slots(np.array(temp_tags))\n",
    "    \n",
    "    def load_valid(self, path):\n",
    "        for line in open(path, 'r'):\n",
    "            words=line.split('\\t')[0].strip().split()\n",
    "            tags =line.split('\\t')[1].strip().split()\n",
    "            temp_utt = list()\n",
    "            temp_tags = list()\n",
    "            for i in range(len(words)):\n",
    "                if words[i] not in self.dictionary.word2idx :\n",
    "                    temp_utt.append(1) \n",
    "                else:\n",
    "                    temp_utt.append(self.dictionary.word2idx[words[i]])\n",
    "                if tags[i] not in self.dictionary.tag2idx :\n",
    "                    temp_tags.append(1) \n",
    "                else:\n",
    "                    temp_tags.append(self.dictionary.tag2idx[tags[i]])\n",
    "            self.valid.add_utterance(np.array(temp_utt))\n",
    "            self.valid.add_slots(np.array(temp_tags))\n",
    "            \n",
    "    def load_test(self, path):\n",
    "        for line in open(path, 'r'):\n",
    "            words=line.split('\\t')[0].strip().split()\n",
    "            tags =line.split('\\t')[1].strip().split()\n",
    "            temp_utt = list()\n",
    "            temp_tags = list()\n",
    "            for i in range(len(words)):\n",
    "                if words[i] not in self.dictionary.word2idx :\n",
    "                    temp_utt.append(1) \n",
    "                else:\n",
    "                    temp_utt.append(self.dictionary.word2idx[words[i]])\n",
    "                if tags[i] not in self.dictionary.tag2idx :\n",
    "                    temp_tags.append(1) \n",
    "                else:\n",
    "                    temp_tags.append(self.dictionary.tag2idx[tags[i]])\n",
    "            self.test.add_utterance(np.array(temp_utt))\n",
    "            self.test.add_slots(np.array(temp_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GolveEmbbedings(object): \n",
    "    \n",
    "    def __init__(self,file_name):\n",
    "        self.words,self.embeddings = self.loadEmbeddings(file_name)\n",
    "        \n",
    "    def loadEmbeddings(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            words = set()\n",
    "            word_to_vec_map = {}\n",
    "            for line in f:\n",
    "                line = line.strip().split()\n",
    "                curr_word = line[0]\n",
    "                words.add(curr_word)\n",
    "                word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        return words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  3,  2,  4, 21,  2,  2,  2,  2,  2, 15, 22,  7],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len  = max([ len(x) for x in  corpus.train.utterances])\n",
    "vocab_size = len(corpus.dictionary.word2idx)\n",
    "tag_vocab_size = len(corpus.dictionary.tag2idx)\n",
    "embedding_size = 50\n",
    "corpus.train.pad_utts(time_length=max_len)\n",
    "corpus.train.pad_tags(time_length=max_len)\n",
    "corpus.valid.pad_utts(time_length=max_len)\n",
    "corpus.valid.pad_tags(time_length=max_len)\n",
    "corpus.test.pad_utts(time_length=max_len)\n",
    "corpus.test.pad_tags(time_length=max_len)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = corpus.train.padded_utterances\n",
    "X_valid = corpus.valid.padded_utterances\n",
    "X_test = corpus.test.padded_utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  4  5  6  7  8  5  9 10 11 12]\n",
      "[2 2 2 2 2 2 3 2 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "print(corpus.train.utterances[0])\n",
    "print(corpus.train.tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (4478, 48)\n",
      "Dev shape (500, 48)\n",
      "Test shape (893, 48)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape \" + str(X_train.shape))\n",
    "print(\"Dev shape \" + str(X_valid.shape))\n",
    "print(\"Test shape \" + str(X_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = corpus.train.get_one_hot_tags(tag_vocab_size)\n",
    "Y_valid = corpus.valid.get_one_hot_tags(tag_vocab_size)\n",
    "Y_test = corpus.test.get_one_hot_tags(tag_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label shape (4478, 48, 143)\n",
      "Dev label shape (500, 48, 143)\n",
      "Test label shape (893, 48, 143)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train label shape \" + str(Y_train.shape))\n",
    "print(\"Dev label shape \" + str(Y_valid.shape))\n",
    "print(\"Test label shape \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist_train =  pd.Series([x.shape[0] for x in corpus.train.utterances])\n",
    "sns.distplot(dist_train, hist=True, kde=True, color='b', label='doc len')\n",
    "plt.title('train query length'); plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkr6ISB5R0hcRySNK+iIieeT/AxESQtxTnzPwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist_valid =  pd.Series([x.shape[0] for x in corpus.valid.utterances])\n",
    "sns.distplot(dist_valid, hist=True, kde=True, color='b', label='doc len')\n",
    "plt.title('valid query length'); plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmYFOXV9/HvYWQRQUDEBQYFgiig\ngDigKCIuIBqFaDDiEvWNCRqXJ8tjEkzyupCYRH00xsQ3CQYN0fioMVFBRxZFxR0GApgBkRERBhUQ\nFGWH4bx/3DXatMNMz9bVy+9zXX11d1V11amCOX33Xfdi7o6IiOSHJnEHICIi6aOkLyKSR5T0RUTy\niJK+iEgeUdIXEckjSvoiInlESV8kDcysi5m5me0Vw7EvM7OX031cyUxK+tLozGy5mZ3WAPtR8qpB\nnF8ukh2U9EXqQElVspWSvjQqM3sAOASYYmYbzezH0fLjzOxVM/vEzBaY2dCEz1xmZsvM7DMze9fM\nLjKznsCfgEHRfj7Zw/G6mtmL0WdnmNkfzOzBaN1QMytP2v7zXyFm1sTMxpnZO2a2zsweNbP9onWV\nJejLzWwFMNPMnjaza5P2t9DMzknhurQxs4lm9oGZrTKzX5pZQcL5v2xm/2NmH0fX4Iykc5wVneOz\nZnZP5TkCs6LnT6LrNCjhc1XuT/KLkr40Knf/JrACONvdW7n7bWbWCXga+CWwH3Ad8E8z62Bm+wB3\nA2e4e2vgeGC+uy8GrgRei/bTdg+HfAiYC+wP/AK4tBbhXgt8DTgJ6Ah8DNyTtM1JQE/gdGAScHHl\nCjPrC1SeW03+CuwEugNHA8OBbyesPxZYEp3HbcBEM7No3UPAbKA9cBPwzYTPDYme20bX6bUU9id5\nRElf4nAxUOzuxe6+y91nACXAmdH6XcCRZra3u3/g7qWp7NTMDgEGAP/X3be5+yxgSi3iuhL4mbuX\nu/s2QkIdnVSVc5O7b3L3LcBkoIeZHRat+ybwiLtvryHOAwnn+v1oX2uA3wJjEjZ7z93vdfcKwpfL\nwcCBCed4g7tvd/eXozhqUuX+Uvic5BglfYnDocB5UdXOJ1FVzWDgYHffBJxPSMAfRFUoR6S4347A\nx9E+Kr1Xy7geT4hpMVDB7slxZeULd98KPAJcbGZNgAuAB1I8TlPC+VUe68/AAQnbfJhwnM3Ry1aE\nc1yfsGy3mKqxp/1JntHNKEmH5KFcVwIPuPt3qtzYfRowzcz2JlQB3QucWMV+kn0AtDOzfRIS/yEJ\nn9sEtKzcOKpD75AU17fc/ZXkHZtZlz2cyyRCon8Z2JxQnVKdlcA2YH9335nC9ok+APYzs5YJybtz\nwnoNmyvVUklf0mE10C3h/YPA2WZ2upkVmFmL6CZroZkdaGajorr9bcBGQnVP5X4KzaxZVQdx9/cI\n1UQ3m1kzMxsMnJ2wydtACzP7qpk1BX4ONE9Y/yfgFjM7FCC6xzCquhOLkvwu4A5SK+Xj7h8A04E7\nzGzf6AbyV8zspBQ+W3mON0XnOCjpHNdG8XSr6vMiSvqSDr8Gfh5VZVzn7iuBUcBPCUlqJfAjwv/H\nJsAPgfeB9YQbp9+N9jMTKAU+NLOP9nCsCwk3LdcDNwJ/q1zh7huAq4C/AKsIJf/E1jy/I9SPTzez\nz4DXo33V5G/AUYQvs1RdAjQDFhFuGD9GqGdPxUXAIGAd4ZfQI4QvyMqqm1uAV6LrfVwtYpI8YJpE\nRXKZmd0EdHf3i2vath7HuAQY6+6DG+sYNRz/EeAtd78xjuNLdlFJX6QezKwl4dfDhDQec0BUHdTE\nzEYQfjU9ka7jS3ZT0hepIzM7nVA9tZrQdj5dDgJeINzvuBv4rrv/O43Hlyym6h0RkTyikr6ISB7J\nuHb6+++/v3fp0iXuMEREssrcuXM/cvcONW2XcUm/S5culJSUxB2GiEhWMbOUep+rekdEJI8o6YuI\n5BElfRGRPJJSnX7UAeR3QAHwF3f/TdL6IcBdQB9gjLs/lrDuEEK3986EwaDOdPflDRK9iOSkHTt2\nUF5eztatW+MOJeO0aNGCwsJCmjZtWqfP15j0o5EI7wGGEcYpmWNmk919UcJmK4DLCJNhJPsbcIu7\nzzCzVnwxeJaISJXKy8tp3bo1Xbp0QXO9fMHdWbduHeXl5XTt2rVO+0ilemcgUObuy6LJIR4mdPtO\nDGS5uy8kKaGbWS9gr2iSDNx9Y9I44CIiX7J161bat2+vhJ/EzGjfvn29fgGlkvQ7sfskDeXRslT0\nIMzV+S8z+7eZ3V45D2giMxtrZiVmVrJ27doUdy0iuUwJv2r1vS6NfSN3L8LkF9cRpnjrRqgG2o27\nT3D3Incv6tChxr4FIiJSR6ncyF3F7jPzFEbLUlFOmNR6GYCZPQEcB0ysTZAikt8mNPAYpmPH1m77\nm266iVatWnHddVXdtkxdq1at2LhxY732UV+pJP05wGFm1pWQ7McQJqpIxRygrZl1cPe1wCmEWX8k\nC9T0h1bbPxwRiV+N1TvRHJ7XANMIE0U/6u6lZjbezEbC5+N7lwPnAX82s9LosxWEqp3nzOxNwAjz\nnYqIZLRbbrmFHj16MHjwYJYsWfL58vnz53PcccfRp08fzjnnHD7++GMAysrKOO200+jbty/9+/fn\nnXfeqXb/t99+OwMGDKBPnz7ceGOY/2b58uX07NmT73znO/Tu3Zvhw4ezZcuWBj2vlOr03b3Y3Xu4\n+1fc/ZZo2Q3uPjl6PcfdC919H3dv7+69Ez47w937uPtR7n5Z1AJIRCRjzZ07l4cffpj58+dTXFzM\nnDlzPl93ySWXcOutt7Jw4UKOOuoobr75ZgAuuugirr76ahYsWMCrr77KwQfvefbL6dOns3TpUmbP\nns38+fOZO3cus2bNAmDp0qVcffXVlJaW0rZtW/75z3826Lll3IBrIiJxe+mllzjnnHNo2bIlACNH\njgRgw4YNfPLJJ5x0UpjD/tJLL+W8887js88+Y9WqVZxzzjlA6EBVnenTpzN9+nSOPvpoADZu3MjS\npUs55JBD6Nq1K/369QPgmGOOYfny5Q16bkr6IiJp5u5cf/31XHHFFbstX758Oc2bN//8fUFBQTzV\nOyIi+WTIkCE88cQTbNmyhc8++4wpU6YA0KZNG9q1a8dLL70EwAMPPMBJJ51E69atKSws5IknwlTF\n27ZtY/PmPfdDPf3007nvvvs+b8mzatUq1qxZ08hnFaikLyIZL90txfr378/5559P3759OeCAAxgw\nYMDn6yZNmsSVV17J5s2b6datG/fffz8QvgCuuOIKbrjhBpo2bco//vEPunXrVuX+hw8fzuLFixk0\naBAQmnI++OCDFBR8qe9qg8u4OXKLiopck6hkBjXZlLgsXryYnj17xh1Gxqrq+pjZXHcvqumzqt4R\nEckjSvoiInlESV9EMlKmVT1nivpeFyV9Eck4LVq0YN26dUr8SSrH06+pH0B11HpHRDJOYWEh5eXl\naKj1L6ucOauulPRFJOM0bdq0zjNDSfVUvSMikkeU9EVE8oiSvohIHlHSFxHJI0r6IiJ5RElfRCSP\npJT0zWyEmS0xszIzG1fF+iFmNs/MdprZ6CrW72tm5Wb2h4YIWkRE6qbGdvpmVgDcAwwDyoE5ZjbZ\n3RclbLYCuIwwH25VfgHMql+o0hhqGklTRHJLKiX9gUCZuy+L5rd9GBiVuIG7L3f3hcCu5A+b2THA\ngcD0BohXRETqIZWk3wlYmfC+PFpWIzNrAtzBnn8BVG431sxKzKxE3a5FRBpPY9/IvQoodvfy6jZy\n9wnuXuTuRR06dGjkkERE8lcqY++sAjonvC+MlqViEHCimV0FtAKamdlGd//SzWAREWl8qST9OcBh\nZtaVkOzHABemsnN3v6jytZldBhQp4YuIxKfG6h133wlcA0wDFgOPunupmY03s5EAZjbAzMqB84A/\nm1lpYwYtIiJ1k9LQyu5eDBQnLbsh4fUcQrVPdfv4K/DXWkcoIiINRj1yRUTyiJK+iEgeUdIXEckj\nSvoiInlESV9EJI8o6YuI5BElfRGRPKKkLyKSR5T0RUTyiJK+iEgeUdIXEckjSvoiInlESV9EJI8o\n6YuI5BElfRGRPKKkLyKSR5T0RUTySEozZ5nZCOB3QAHwF3f/TdL6IcBdQB9gjLs/Fi3vB/wR2Beo\nAG5x90caLnyJ04QJe143dmz64hCR1NVY0jezAuAe4AygF3CBmfVK2mwFcBnwUNLyzcAl7t4bGAHc\nZWZt6xu0iIjUTSol/YFAmbsvAzCzh4FRwKLKDdx9ebRuV+IH3f3thNfvm9kaoAPwSb0jFxGRWkul\nTr8TsDLhfXm0rFbMbCDQDHininVjzazEzErWrl1b212LiEiK0nIj18wOBh4A/o+770pe7+4T3L3I\n3Ys6dOiQjpAkRe7w0UewdWvckYhIQ0ilemcV0DnhfWG0LCVmti/wNPAzd3+9duFJXDZsgIcegrIy\n2LgR9t0XLr0Ujjwy7shEpD5SKenPAQ4zs65m1gwYA0xOZefR9o8Df6ts0SOZb9s2uOceWLQI+vaF\n88+H1q3h97+Hhx+GXV/6rSYi2aLGkr677zSza4BphCab97l7qZmNB0rcfbKZDSAk93bA2WZ2c9Ri\n5xvAEKC9mV0W7fIyd5/fGCcj9bdrF0ycCCtWwFVXQZ8+YfmJJ8K//gUzZ8L++8Npp8Ubp4jUTUrt\n9N29GChOWnZDwus5hGqf5M89CDxYzxgljYqLYcGCULqvTPgATZvCN74R6vcffxx69YKOHeOLU0Tq\nRj1y5XObNsH06dC/P5xyypfXm8E3vwktWsD990NFRfpjFJH6UdKXzz33XKjPP+usPW+z775w8cWh\n+mfGjPTFJiINI6XqHcl9mzeHpN+/P3SqoRfG0UfDUUfBtGkwZAi0bPnlbaobogE0TINIXFTSFyDc\noN26Fc48M7XtR44MXxTPPtu4cYlIw1LSF7ZvD6X8vn2hc+eatwc45JDwq+C550I7fhHJDkr6wsKF\nodR+8sm1+9zZZ4d7ANOnN05cItLwlPSF11+Htm3h8MNr97mOHWHAAHj+eZX2RbKFkn6e++wzKC2F\ngQOhSR3+N4wYEaqHXnihwUMTkUagpJ/n5swJvXCPO65un+/UKXTimjkzVPWISGZT0s9zb7wRbt7W\n1EyzOiNGhI5dr7zScHGJSONQ0s9jb70Fy5fDscfWbz9f+Qp07x46a6mXrkhmU9LPY48+GoZWGDiw\n/vsaMQLWrw/VRSKSuZT089iTT0K3btCmTf33deSRoTXPtGkaelkkkynp56mVK2HevN1H0qwPs1Da\nf/99ePPNhtmniDQ8Jf08NWVKeO7Xr+H2WVQE7duH0r6IZCYl/Tz15JPQowccdFDD7bOgAIYNg3fe\nCdMsikjmUdLPQxs2hF60o0Y1/L5POCFMrVhcXPO2IpJ+KSV9MxthZkvMrMzMxlWxfoiZzTOznWY2\nOmndpWa2NHpc2lCBS91NmwY7doSRMhtas2ZhKsXSUli2rOH3LyL1U2PSN7MC4B7gDKAXcIGZ9Ura\nbAVwGfBQ0mf3A24EjgUGAjeaWbv6hy318eST0KEDDBrUOPsfOhRatfrivoGIZI5USvoDgTJ3X+bu\n24GHgd0qBtx9ubsvBJIb650OzHD39e7+MTADGNEAcUsdVVTA1Klh3PyCgsY5RosWMHw4LFoU6vdF\nJHOkMnNWJ2BlwvtyQsk9FVV9th4d/qW2kmewevfd0ImqadOaZ7eqj6FDQw/dp56C732v8Y4jIrWT\nETdyzWysmZWYWcnatWvjDienlZaGNvU9ezbucZo3/6K0v2RJ4x5LRFKXStJfBSTOp1QYLUtFSp91\n9wnuXuTuRR06dEhx11IXpaVw6KGhzr2xDR0K7drBY4+pl65Ipkgl6c8BDjOzrmbWDBgDTE5x/9OA\n4WbWLrqBOzxaJjHYtClU7/TunZ7jNWsGX/sarFgBJSXpOaaIVK/GpO/uO4FrCMl6MfCou5ea2Xgz\nGwlgZgPMrBw4D/izmZVGn10P/ILwxTEHGB8tkxi89Ra4py/pQxjMrXNneOKJ0ExUROKVyo1c3L0Y\nKE5adkPC6zmEqpuqPnsfcF89YpQGUloKLVtCly7pO2aTJvD1r8Ndd4UOYcOHp+/YIvJlGXEjVxqf\ne0j6PXs2XlPNPenZM4zC+cwzoYpJROKTUklfst/778Mnn0Cv5G51aXLuufCLX8DTT8M3vlHz9tU1\nJx07tuHiEsk3KunnidLS8JzO+vxEnTrB8ceHCdTVKlckPkr6eWLRojDJSbsYB8EYOTJULT3xRHwx\niOQ7Jf08sG0bLF0aXym/Utu2YejlkhKYPTveWETylZJ+Hnj7bdi5M/6kD6H1TuvW8OMfh5vLIpJe\nSvp5oLQ0jLXTvXvckYTB2M4+G158MYzLIyLppaSfB0pL4fDDQ+LPBIMHh1m7fvKT8AtERNJHST/H\nrV0La9ZkRtVOpYIC+M1vYPFiuP/+uKMRyS9K+jlu0aLwnElJH8KYPCecADfcABs3xh2NSP5Q0s9x\npaWw//5wwAFxR7I7M7j9dvjwQ7jzzrijEckfSvo5bPv2MMhar14hyWaaQYPCuDy33QarV8cdjUh+\nUNLPYa++GtroZ1rVTqJf/zrEOH583JGI5Acl/Rw2bVoY5fLww+OOZM8OOwy+/W24994w7r6INC4l\n/Rw2dWpom7/33nFHUr2f/jQ8/+pX8cYhkg+U9HPUhx/C/PnxjapZG507h9L+fffBe+/FHY1IblPS\nz1HTp4fnTK7PT3T99eFms0r7Io1LST9HTZ0KBx4IhVXOZ5Z5Ekv7y5fHHY1I7kop6ZvZCDNbYmZl\nZjauivXNzeyRaP0bZtYlWt7UzCaZ2ZtmttjMrm/Y8KUqFRWhpD98eLiRmy2uvz7Eq9K+SOOpMSWY\nWQFwD3AG0Au4wMySa4ovBz529+7Ab4Fbo+XnAc3d/SjgGOCKyi8EaTxvvAHr1sGZZ8YdSe0UFoZZ\nse6/Hz76KO5oRHJTKuXAgUCZuy9z9+3Aw8CopG1GAZOi148Bp5qZAQ7sY2Z7AXsD24FPGyRy2aOn\nngrj24wYEXcktTduXIi9uDjuSERyUypJvxOwMuF9ebSsym3cfSewAWhP+ALYBHwArAD+x93XJx/A\nzMaaWYmZlazVXHr1NmUKnHhimLQk23TqFEr7r72maRVFGkNj1/gOBCqAjkBX4L/NrFvyRu4+wd2L\n3L2oQ4cOjRxSblu+HP7znzBmfbYaNy7U7U+dGnckIrknlaS/Cuic8L4wWlblNlFVThtgHXAhMNXd\nd7j7GuAVoKi+QcuePf10eD7rrHjjqI+OHcMk6q+/Dhs2xB2NSG7ZK4Vt5gCHmVlXQnIfQ0jmiSYD\nlwKvAaOBme7uZrYCOAV4wMz2AY4D7mqo4OXLpkwJE5T06BF3JPUzbBi89BI8+2wYlC3RhAnVf3bs\n2MaLSyTb1VjSj+rorwGmAYuBR9291MzGm9nIaLOJQHszKwN+CFQ267wHaGVmpYQvj/vdfWFDn4QE\nGzfC889ndym/0gEHwDHHwKxZsGVL3NGI5I5USvq4ezFQnLTshoTXWwnNM5M/t7Gq5VI71ZVsE0u1\nM2aE4ZRzIekDnH46lJSE+XSzsSWSSCbKoq47UpOnnoI2bcIctLngkEPC2EHPPRe+zESk/pT0c8Su\nXeEm7ogRmTMBekMYMQI+/TQ04RSR+lPSzxElJWH2qWxuqlmVHj2gS5cwrERFRdzRiGQ/Jf0cMWVK\naNuea3XfZuGcPvoI5s2LOxqR7KeknyOeegpOOAHat487kobXt28YMXTqVHCPOxqR7KaknwNWrgwT\npuRKq51kTZqEljzl5bBoUdzRiGQ3Jf0cUNkLN9fq8xMNHAj77hs6a4lI3Snp54ApU6BbNzjiiLgj\naTxNm8LJJ4eS/qrkQUBEJGVK+lnu009D6XfUqHDTM5cNGRKS/4wZcUcikr2U9LNccXHouJQ8Pk0u\natUqDMQ2e7YGYhOpKyX9LPevf8FBB8GgQXFHkh6nnho6oj3/fNyRiGQnJf0stn17KOl/7WvZNRdu\nfRx4IPTpEwZi09AMIrWXJ6kiNy1eDJs2wbnnxh1Jeg0bFs5bQzOI1J6SfhabNw/atYOhQ+OOJL26\nd4dDDw03sHftijsakeyipJ+lKipg4UIYOTK3BlhLhVko7a9ZA2++GXc0ItlFST9LvfUWbN6cf1U7\nlfr3D79y1FlLpHaU9LNUSQm0aBGGJ8hHBQWhJc/bb8N778UdjUj2SCnpm9kIM1tiZmVmNq6K9c3N\n7JFo/Rtm1iVhXR8ze83MSs3sTTNr0XDh56edO8NYO/36QfPmcUcTn8GDwxefOmuJpK7GpG9mBYS5\nbs8AegEXmFmvpM0uBz529+7Ab4Fbo8/uBTwIXOnuvYGhwI4Giz5PLV4cqnaKiuKOJF577x1GFp07\nF9avjzsakeyQSkl/IFDm7svcfTvwMDAqaZtRwKTo9WPAqWZmwHBgobsvAHD3de6uqTDqqaQEWraE\nnj3jjiR+p54ahlueOTPuSESyQypJvxOwMuF9ebSsym3cfSewAWgP9ADczKaZ2Twz+3FVBzCzsWZW\nYmYla9eure055JUdO76o2tkrpWntc1v79uGm7ksvwdatcUcjkvka+0buXsBg4KLo+RwzOzV5I3ef\n4O5F7l7UoUOHRg4pu5WWhuSW71U7iYYNC9fk5ZfjjkQk86WS9FcBnRPeF0bLqtwmqsdvA6wj/CqY\n5e4fuftmoBjoX9+g89mcObDPPrk9jHJtde0aOmzNnKl5dEVqkkrSnwMcZmZdzawZMAaYnLTNZODS\n6PVoYKa7OzANOMrMWkZfBicBmvuojrZsgQULQim/oCDuaDLLsGGwbh38+99xRyKS2WqsFXb3nWZ2\nDSGBFwD3uXupmY0HStx9MjAReMDMyoD1hC8G3P1jM7uT8MXhQLG7P91I55Lz5s0LdfrHHRd3JJmn\nTx844IDQfPPPf65+boGxY+t+nAkTGme/IumS0q1Ady8mVM0kLrsh4fVW4Lw9fPZBQrNNqac33giJ\nrWvXuCPJPE2ahJY8//u/8M47obpHRL5MPXKzxPr1offpwIG5P0NWXR1/fLjfoc5aInumpJ8lZs8O\n7dFVtbNnzZqFKRUXLIDVq+OORiQzKelnAXd4/fUw+blatFbv5JPDTe7nnos7EpHMpKSfBd59Fz74\nIH+mRKyPNm3g2GPh1Vdh48a4oxHJPEr6WeDll8PAagMGxB1JdjjttNDK6cUX445EJPMo6We4Tz8N\nHbKKisIAY1Kzjh2hd2944YWQ/EXkC0r6Ge6hh8IE4CeeGHck2WXYsPCFqXl0RXanpJ/h7r0XCguh\nS5e4I8kuRxwRrtnUqRqaQSSRkn4Gmzs39MIdPFht82vLDL761TA0w+zZcUcjkjmU9DPY3XeHcfOP\nPTbuSLLTUUdB587wzDOwa1fc0YhkBo3IngGqGs9lwwb4+99DXX7LlumPKReYwZlnhrF4SkpCb2aR\nfKeSfoZ64YVQOj3llLgjyW79+oXWPFOmhLmFRfKdkn4G2r4dZs0K1RMHHhh3NNmtSRM491xYsyZc\nU5F8p6Sfgd54I/QmPe20uCPJDUceGVrzPPVUmFBeJJ8p6WeYioowSmTnztCjR9zR5AYzGD06JPxn\nnok7GpF4KelnmDlzwgiRZ56pZpoNqXPnMELpzJmwcGHc0YjER6130qC62ZYSVVTA00+Hzlj9+jVu\nTPno618PE8tffHFou9+iRdwRiaRfSiV9MxthZkvMrMzMxlWxvrmZPRKtf8PMuiStP8TMNprZdQ0T\ndm6aPTvccDz77HADUhpW69ZwySXw5pvws5/FHY1IPGpMLWZWANwDnAH0Ai4ws15Jm10OfOzu3YHf\nArcmrb8TUG1qNSpL+Z07Q9++cUeTu446Cq66Cu68E558Mu5oRNIvlfLkQKDM3Ze5+3bgYWBU0jaj\ngEnR68eAU81CjbSZfQ14FyhtmJBz0+uvw9q1oZSvuvzGdfvtYdTS0aPhscfijkYkvVJJ+p2AlQnv\ny6NlVW7j7juBDUB7M2sF/AS4uboDmNlYMysxs5K1a9emGnvOqKiA4mI45BDo0yfuaHJfy5bw7LOh\nh+7558Mf/6hB2SR/NHbN8U3Ab9292jmM3H2Cuxe5e1GHPJwP8LXX4KOPYORIlfLTpU0bmDYt9Hi+\n6qow/v6kSbBiRZieUiRXpdJ6ZxXQOeF9YbSsqm3KzWwvoA2wDjgWGG1mtwFtgV1mttXd/1DvyHPE\nzp2hlN+lS+hEJOnTqlVI/I8/DjffDJddFpa3bg1du8JBB4V5ic86C049Va19JDekkvTnAIeZWVdC\nch8DXJi0zWTgUuA1YDQw090d+HzqDzO7CdiohL+7V18Nw/9eeKFK+XFo0iQ05TznnHBfZeHC0Kxz\nxYowL/GDD8Kf/hS+CMaPD7OX6d9JslmNSd/dd5rZNcA0oAC4z91LzWw8UOLuk4GJwANmVgasJ3wx\nSA127Ail/K5dQ/WCxKdJEzj++PBItG0bPP88/P738IMfQP/+odmnpq6UbJVS5yx3LwaKk5bdkPB6\nK3BeDfu4qQ7x5bRXX4WPPw5JRKXH9Kmus9zYsbu/b94cRoyA00+HO+6An/wk3H/50Y+gWbPGjVOk\nMagLUEx27AjjwHzlK9CzZ9zRSE3M4Lrr4MorQ9XPo4/GHZFI3Sjpx+Tll0MpX+3ys0vfvqHk/9JL\n4R6ASLZR0o/Bjh1hwu7u3cOQv5JdRo6Eww4LM5vlYbcSyXJK+jF4/XX45JMwcbdK+dmnoAAuvzy8\nfuKJeGMRqS0l/TSrqAhtww89VHX52axdOxg2LMy9++67cUcjkjol/TSbNy9UCYwYoVJ+ths+PLTf\nf+wx9eKV7KGkn0buoS7/oIM0Xn4uaNEi3IgvK4MFC+KORiQ1SvppVFoK5eWhlK/x8nPD4MFh8vqn\nnlJpX7KDUk8aPfdcGOhrwIC4I5GGUlAQOm6tXAnTp8cdjUjNNF1imnz4ISxaFJr77aWrnlMGDoTJ\nk+F734Mf/nDP2yX39hWJg0r6aTJzZkj2J55Y87aSXZo2hdNOgyVL1JJHMp+Sfhps3hza5g8YAPvu\nG3c00hhOPDFMzjJ1atyRiFTQtgoaAAANb0lEQVRPST8NXn01jNZ4yilxRyKNpUULOOmk0Ipn9eq4\noxHZMyX9RlZREYbm7d49TIcouevkk8ON3eeeizsSkT1T0m9kTz8dhuJVKT/3tWkTbuq++ipsrHaC\nUJH4KOk3srvvDl321RkrP5x2WhhQb9asuCMRqZqSfiMqLQ0/9YcODT/7Jfd16gS9eoUqvR074o5G\n5MtSSvpmNsLMlphZmZmNq2J9czN7JFr/hpl1iZYPM7O5ZvZm9JxXlRx33x1u8A0eHHckkk7DhsGn\nn8KcOXFHIvJlNSZ9MysA7gHOAHoBF5hZr6TNLgc+dvfuwG+BW6PlHwFnu/tRhInTH2iowDPd+vXw\nwANw8cXQqlXc0Ug69ewJhYXw7LMamkEyTyol/YFAmbsvc/ftwMPAqKRtRgGTotePAaeambn7v939\n/Wh5KbC3mTVviMAz3cSJsGULXHtt3JFIupmFuv1Vq2Dx4rijEdldKkm/E7Ay4X15tKzKbdx9J7AB\naJ+0zdeBee6+rW6hZo+dO+EPfwh1+X36xB2NxKGoKHTEmzEj7khEdpeWG7lm1ptQ5XPFHtaPNbMS\nMytZmwPzz02eHCbP/t734o5E4tK0aWi3v2hRKPGLZIpUkv4qoHPC+8JoWZXbmNleQBtgXfS+EHgc\nuMTd36nqAO4+wd2L3L2oQ4cOtTuDDHT33WFmrLPPjjsSidNJJ0GzZirtS2ZJJenPAQ4zs65m1gwY\nA0xO2mYy4UYtwGhgpru7mbUFngbGufsrDRV0Jps/H158Ea65Rs00890++4SWW2+8oQnUJXPUmPSj\nOvprgGnAYuBRdy81s/FmNjLabCLQ3szKgB8Clc06rwG6AzeY2fzocUCDn0UGufPOMPBW5cTZkt9O\nPz18+RcXxx2JSJDSyO7uXgwUJy27IeH1VuC8Kj73S+CX9Ywxa7zzDjz0UKjLb9cu7mgkE7RtC0OG\nhM5aZWVhDCaROKlHbgP6zW/CmPnXXRd3JJJJKkv7v/hF3JGIKOk3mBUrYNIk+Pa34eCD445GMkmb\nNuGm7oMPhqE5ROKkpN9AbrstPP/4x/HGIZnpjDNC8r/2WvXSlXgp6TeAd96Be++FSy/VmPlStVat\n4JZbQt3+I4/EHY3kMyX9BvDDH4b22DffHHckksnGjoX+/eG//xs++yzuaCRfpdR6R/Zs6tTQA/fW\nW6Fjx7ijkUxWUAD33AODBsG4ceF1ukyYsOd1Y8emLw6Jn0r69bB9O3z/+6EZnoZckFQcdxz84Afw\n//6fqnkkHkr69TB+PCxZAnfdBc3zYuxQaQi33grHHx9aer31VtzRSL5R9U4dzZgBv/oVfOtb8NWv\nVv/zWSRR06ahlH/00XDOOTBzZs3NfGv6/6UqGkmVSvp18MEHcNFFYbKM3/8+7mgkGxUWwj//CStX\nhvF5li2r/z4rKuD998OMXXPnhh7AmqBdkqmkX0uffQbnnhv+mJ5/PoyzI5KKqkrr114bRmXt3x8e\nfzwMx5yqigpYvjxM1PLAA2Fgt+R5eZs0gX79YL/9YODAMPqr5Dcl/VrYtAnOOiuUpB59FHr3jjsi\nyXZdu8KPfhQm3TnllFDdc+ONYfIds923dYfVq8MY/W+9Fe4nbd0atisqCo0JunX7ohXZhg2htD9r\nFrzwQpi+sUuXMKvXMceELwTJP0r6Kfr001DCf/ll+Pvfw2uRhtCxI9x0U0jSv/51KPEfdFC42Vv5\nS/L118NkLFu2hPf77w8DBoQqxiOOCC2CqnPXXWEfs2bBX/4C06eH/8M9ezbqqUkGUtJPweLFoQRW\nVgZ//SuMGRN3RJJrmjWDn/0stOh56il47rlQL79zJ+zaFdr4DxgAnTuHRF3buYZatgy/JIYODb9U\nn3wyfBH07Bn2e/TRjXJakoGU9KvhDn/7W5gQxSy0yd+yRS11pPEceGCYiyF5PoaG+j/XpAkce2y4\nh/Dii2Gc//794cILwyig3bo1zHEkcynp78Hbb8N3vxua051wQpj6UGPkS2NKZ2GiadNQt3/88bBm\nTSj1/+Mf8J3vhKHBu3ZNXyySXrqVk2TFitDmuXfv8PP6j38M9aBK+JKLWrYM/U3KykKfk3vvDT3M\nx4wJrdN27Yo7QmloKukTqnFeeSUk+H/8I1TlXHEF/Pzn4YaaSC6r/IXRv38o4c+cGer8H3kkFHa+\n9S0488zQn6BZs3hjbSj53NktpaRvZiOA3wEFwF/c/TdJ65sDfwOOAdYB57v78mjd9cDlQAXwX+4+\nrcGir4dt22D2bJgyJbSWKCuDffcNyf5HP9IQyZKf2rWDr389VGcuWBBa/Nx9N9xxR/hVMGBAGD+o\nTx84/HDo0QNat4476trZsQM++gjWrw+Pdevgk09C35tNm8LN84kTQ+GvTZsvHm3bQvv2obVVp07h\nuWPHkDeSm9dmshqTvpkVAPcAw4ByYI6ZTXb3RQmbXQ587O7dzWwMcCtwvpn1AsYAvYGOwLNm1sPd\nKxr6RCCU2HfuDDdbt24Nz5s2hX/gNWvg3Xdh6VJ4802YNy8MmLbXXqFVw7hx4SftPvs0RmQi2aVZ\ns5DgBwwIf0tLloS+AcuWhWbLFQl/wR07huR/8MGhVdEBB4Tn/fYL+2naNDz22iv8jW7eHP4uN2/+\n8uutW794lJaG7QsKwmcLCr543axZuB+x997h0bJleDYLf/eVj82bYe3a0PO5vDw8f/jhlyeyad06\nzHnQsmXY96ZNoWprzZov9rNly5c7v0HIGZVfAIlfBh07huvQqtXuj2bNwnk0afLFOaXzSyOVkv5A\noMzdlwGY2cPAKCAx6Y8CbopePwb8wcwsWv6wu28D3jWzsmh/rzVM+F9YvTpc5JrqIPffP7Rr/q//\nCkPcnnJK+AYXkaq1aAF9+4YHhMS3dm34m1u9OpSCly4NTUHXrAl9WuqiefNwrMrH1q0hMVZUhMJc\n5fPOnSGGZ55Jbb+tWoWmroWFcOSRITEvXx6+lNq3D79uUq222ro19KcYMiT0m3j//fCofF3Zn2Lb\nttqdu1lI/sceG75UG5N5DXO3mdloYIS7fzt6/03gWHe/JmGb/0TblEfv3wGOJXwRvO7uD0bLJwLP\nuPtjSccYC1TWoh1OqCL6qN5nl377k51xQ/bGrrjTL1tjz/W4D3X3GntwZMSNXHefAHx+a8XMSty9\nKMaQ6iRb44bsjV1xp1+2xq64g1SabK4COie8L4yWVbmNme0FtCGU1lP5rIiIpEkqSX8OcJiZdTWz\nZoQbs5OTtpkMXBq9Hg3M9FBvNBkYY2bNzawrcBgwu2FCFxGR2qqxesfdd5rZNcA0QpPN+9y91MzG\nAyXuPhmYCDwQ3ahdT/hiINruUcJN353A1Sm23MnWgQ6yNW7I3tgVd/pla+yKmxRu5IqISO7QMAwi\nInlESV9EJI9kXNI3sxFmtsTMysxsXNzxpMrMlpvZm2Y238xK4o6nOmZ2n5mtifpXVC7bz8xmmNnS\n6DnjhpjbQ9w3mdmq6LrPN7Mz44yxKmbW2cyeN7NFZlZqZt+Llmf0Na8m7my45i3MbLaZLYhivzla\n3tXM3ojyyyNR45SMUU3cfzWzdxOueb86H8TdM+ZBuFH8DtANaAYsAHrFHVeKsS8H9o87jhRjHQL0\nB/6TsOw2YFz0ehxwa9xxphj3TcB1ccdWQ9wHA/2j162Bt4FemX7Nq4k7G665Aa2i102BN4DjgEeB\nMdHyPwHfjTvWFOP+KzC6IY6RaSX9z4d8cPftQOWQD9KA3H0WoZVVolHApOj1JOBraQ0qBXuIO+O5\n+wfuPi96/RmwGOhEhl/zauLOeB5sjN42jR4OnEIYKgYy85rvKe4Gk2lJvxOwMuF9OVnyn4zwDzPd\nzOZGw0pkmwPd/YPo9YfAgXEGU0vXmNnCqPono6pIkplZF+BoQgkua655UtyQBdfczArMbD6wBphB\nqEX4xN13RptkZH5JjtvdK6/5LdE1/200snGdZFrSz2aD3b0/cAZwtZkNiTuguvLw2zJb2vL+EfgK\n0A/4ALgj3nD2zMxaAf8Evu/uuw1LlsnXvIq4s+Kau3uFu/cjjAQwEDgi5pBSkhy3mR0JXE+IfwCw\nH/CTuu4/05J+1g7b4O6rouc1wOOE/2TZZLWZHQwQPa+JOZ6UuPvq6I9kF3AvGXrdzawpIXH+3d3/\nFS3O+GteVdzZcs0rufsnwPPAIKBtNFQMZHh+SYh7RFTV5h5GLL6felzzTEv6qQz5kHHMbB8za135\nGhgO/Kf6T2WcxKE0LgWejDGWlFUmzcg5ZOB1j4YZnwgsdvc7E1Zl9DXfU9xZcs07mFnb6PXehPlA\nFhOS6Ohos0y85lXF/VZC4cAI9yHqfM0zrkdu1PzrLr4Y8uGWmEOqkZl1I5TuIQxt8VAmx21m/wsM\nJQzZuhq4EXiC0LLhEOA94BvunlE3TfcQ91BCNYMTWlBdkVBPnhHMbDDwEvAmUDnjw08J9eMZe82r\nifsCMv+a9yHcqC0gFG4fdffx0d/qw4Qqkn8DF0el54xQTdwzgQ6E1j3zgSsTbvjW7hiZlvRFRKTx\nZFr1joiINCIlfRGRPKKkLyKSR5T0RUTyiJK+iEgeUdIXEckjSvoiInnk/wPomnYQyUUBJwAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist_test =  pd.Series([x.shape[0] for x in corpus.test.utterances])\n",
    "sns.distplot(dist_test, hist=True, kde=True, color='b', label='doc len')\n",
    "plt.title('test query length'); plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/seaborn/categorical.py:1460: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb04dbddc18>"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.Series([x[0]for x in corpus3.train.tags])\n",
    "sns.countplot(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SlotFilingModel(object):\n",
    "    \n",
    "    def __init__(self, vocab_size, tag_vocab_size, max_length_sequence, embedding_size,idx2tags,model_path, batch_size= 32, nb_epochs=10, early_stop=True):\n",
    "        self.model = self.model(vocab_size,tag_vocab_size,max_length_sequence,embedding_size)\n",
    "        self.model_path = model_path+'.h5'\n",
    "        self.batch_size =batch_size\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.loss = 'categorical_crossentropy'\n",
    "        self.optimizer = 'adam'\n",
    "        self.early_stop = early_stop\n",
    "        self.idx2tags = idx2tags\n",
    "        self.model.compile(loss=self.loss, optimizer=self.optimizer, metrics=['accuracy',f1,recall,precision])\n",
    "        self.model.summary()\n",
    "    \n",
    "    def model(self,vocab_size,tag_vocab_size,max_length_sequence,embedding_size):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X_train,Y_train,X_valid,Y_valid):\n",
    "        early_stopping = EarlyStopping(monitor='val_loss',min_delta=0.01,patience=4,verbose=1)\n",
    "        callbacks_list = [early_stopping]\n",
    "        if self.early_stop :\n",
    "            self.model.fit(X_train,Y_train,batch_size=self.batch_size,epochs=self.nb_epochs,callbacks=callbacks_list,validation_data=[X_valid,Y_valid],shuffle=True)\n",
    "        else:\n",
    "            self.model.fit(X_train,Y_train,batch_size=self.batch_size,epochs=self.nb_epochs,validation_data=[X_valid,Y_valid],shuffle=True)\n",
    "        self.save(self.model_path)\n",
    "        \n",
    "    def evaluate(self,X,Y):\n",
    "        if os.path.exists(self.model_path):\n",
    "            self.load(self.model_path)\n",
    "        loss, acc,f1,recall,precision = self.model.evaluate(X, Y)\n",
    "        print(\"accuracy = {} - f1-score = {} - recall = {} - precision = {}\".format(acc,f1,recall,precision))        \n",
    "        \n",
    "    def predict(self,X):\n",
    "        if os.path.exists(self.model_path):\n",
    "            self.load(self.model_path)\n",
    "        res = []\n",
    "        preds = self.model.predict(X) \n",
    "        for exemple in preds :\n",
    "            res_temp = []\n",
    "            for timestamp in exemple :\n",
    "                res_temp.append(self.idx2tags[np.argmax(timestamp)])\n",
    "            res.append(res_temp)    \n",
    "        return res\n",
    "    \n",
    "    def predict_no_padding(self,X,Y):\n",
    "        if os.path.exists(self.model_path):\n",
    "            self.load(self.model_path)\n",
    "        preds = self.model.predict(X)\n",
    "        res_total = []\n",
    "        pre_total = []\n",
    "        res_intent = []\n",
    "        pre_intent = []\n",
    "        res_slot = []\n",
    "        pre_slot = []\n",
    "        cpt = 0\n",
    "        p=0\n",
    "        for i,y in enumerate(Y):\n",
    "            for j,a in enumerate(y):\n",
    "                t = np.argmax(a)\n",
    "                if t != 0:\n",
    "                    if np.argmax(Y[i][j]) == 2 :\n",
    "                        p+=1\n",
    "                    if X[i][j] == 12:\n",
    "                        res_intent.append(t)\n",
    "                        pre_intent.append(np.argmax(preds[i][j]))\n",
    "                    else :\n",
    "                        res_slot.append(t)\n",
    "                        pre_slot.append(np.argmax(preds[i][j]))\n",
    "                    res_total.append(t)\n",
    "                    pre_total.append(np.argmax(preds[i][j]))\n",
    "                else:\n",
    "                    cpt+=1\n",
    "        print(\"Pourcentage de la classe <pad> :\",cpt/(len(X[0])*len(X)))\n",
    "        print(\"Pourcentage de la classe O :\",p/(len(Y[0])*len(Y)))\n",
    "        print(\"Accuracy totale :\",accuracy_score(res_total,pre_total))\n",
    "        print(\"F1 score totale :\",f1_score(res_total,pre_total,average='weighted'))\n",
    "        print(\"Accuracy intent :\",accuracy_score(res_intent,pre_intent))\n",
    "        print(\"F1 score intent :\",f1_score(res_intent,pre_intent,average='weighted'))\n",
    "        print(\"Accuracy slot :\",accuracy_score(res_slot,pre_slot))\n",
    "        print(\"F1 score slot :\",f1_score(res_slot,pre_slot,average='weighted'))\n",
    "        print('--------------------------------------------------')\n",
    "    \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Layers GRU :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwoGruModel(SlotFilingModel):\n",
    "    \n",
    "    def __init__(self, vocab_size, tag_vocab_size, max_length_sequence, embedding_size,idx2tags,model_path, batch_size= 32, nb_epochs=10, early_stop=True):\n",
    "        super().__init__(vocab_size, tag_vocab_size, max_length_sequence, embedding_size,idx2tags,model_path, batch_size= 32, nb_epochs=10, early_stop=True)\n",
    "        \n",
    "    def model(self,vocab_size,tag_vocab_size,max_length_sequence,embedding_size):\n",
    "        \n",
    "        X_input = Input(shape=(max_length_sequence,), dtype='int32')\n",
    "        X = Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_length_sequence, mask_zero = True)(X_input)\n",
    "        \n",
    "        X = GRU(units = 150, return_sequences = True)(X)    # GRU (use 150 units and return the sequences)\n",
    "        X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n",
    "        X = BatchNormalization()(X)                         # Batch normalization\n",
    "\n",
    "        X = GRU(units = 150, return_sequences = True)(X)    # GRU (use 150 units and return the sequences)\n",
    "        X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n",
    "        X = BatchNormalization()(X)                         # Batch normalization\n",
    "        X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n",
    "\n",
    "        X = TimeDistributed(Dense(tag_vocab_size, activation = \"softmax\"))(X) # time distributed  (sigmoid)\n",
    "        model = Model(inputs = X_input, outputs = X)\n",
    "        return model \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_45 (InputLayer)        (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "embedding_45 (Embedding)     (None, 48, 50)            43550     \n",
      "_________________________________________________________________\n",
      "gru_67 (GRU)                 (None, 48, 150)           90450     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 48, 150)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 48, 150)           600       \n",
      "_________________________________________________________________\n",
      "gru_68 (GRU)                 (None, 48, 150)           135450    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 48, 150)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 48, 150)           600       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 48, 150)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_42 (TimeDis (None, 48, 143)           21593     \n",
      "=================================================================\n",
      "Total params: 292,243\n",
      "Trainable params: 291,643\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_gru = TwoGruModel(vocab_size,tag_vocab_size,max_len,embedding_size,corpus.dictionary.idx2tag,\"two_gru_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4478 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "4478/4478 [==============================] - 68s 15ms/step - loss: 4.0728 - acc: 0.3949 - f1: 0.1536 - recall: 0.0878 - precision: 0.6266 - val_loss: 1.2732 - val_acc: 0.7726 - val_f1: 0.3233 - val_recall: 0.1960 - val_precision: 0.9261\n",
      "Epoch 2/10\n",
      "4478/4478 [==============================] - 56s 12ms/step - loss: 1.6185 - acc: 0.6981 - f1: 0.2807 - recall: 0.1656 - precision: 0.9234 - val_loss: 0.9835 - val_acc: 0.7908 - val_f1: 0.3541 - val_recall: 0.2174 - val_precision: 0.9565\n",
      "Epoch 3/10\n",
      "4478/4478 [==============================] - 58s 13ms/step - loss: 1.2783 - acc: 0.7459 - f1: 0.3067 - recall: 0.1835 - precision: 0.9343 - val_loss: 0.8706 - val_acc: 0.8258 - val_f1: 0.3551 - val_recall: 0.2180 - val_precision: 0.9592\n",
      "Epoch 4/10\n",
      "4478/4478 [==============================] - 53s 12ms/step - loss: 1.1182 - acc: 0.7670 - f1: 0.3200 - recall: 0.1928 - precision: 0.9419 - val_loss: 0.7939 - val_acc: 0.8396 - val_f1: 0.3641 - val_recall: 0.2246 - val_precision: 0.9627\n",
      "Epoch 5/10\n",
      "4478/4478 [==============================] - 63s 14ms/step - loss: 1.0178 - acc: 0.7821 - f1: 0.3269 - recall: 0.1979 - precision: 0.9422 - val_loss: 0.7377 - val_acc: 0.8556 - val_f1: 0.3642 - val_recall: 0.2248 - val_precision: 0.9605\n",
      "Epoch 6/10\n",
      "4478/4478 [==============================] - 57s 13ms/step - loss: 0.9587 - acc: 0.7902 - f1: 0.3309 - recall: 0.2007 - precision: 0.9430 - val_loss: 0.6778 - val_acc: 0.8704 - val_f1: 0.3647 - val_recall: 0.2251 - val_precision: 0.9620\n",
      "Epoch 7/10\n",
      "4478/4478 [==============================] - 50s 11ms/step - loss: 0.9140 - acc: 0.7958 - f1: 0.3334 - recall: 0.2026 - precision: 0.9418 - val_loss: 0.6342 - val_acc: 0.8811 - val_f1: 0.3667 - val_recall: 0.2267 - val_precision: 0.9608\n",
      "Epoch 8/10\n",
      "4478/4478 [==============================] - 49s 11ms/step - loss: 0.8757 - acc: 0.8025 - f1: 0.3359 - recall: 0.2046 - precision: 0.9405 - val_loss: 0.5949 - val_acc: 0.8884 - val_f1: 0.3685 - val_recall: 0.2280 - val_precision: 0.9631\n",
      "Epoch 9/10\n",
      "4478/4478 [==============================] - 50s 11ms/step - loss: 0.8408 - acc: 0.8074 - f1: 0.3385 - recall: 0.2065 - precision: 0.9410 - val_loss: 0.5685 - val_acc: 0.8895 - val_f1: 0.3747 - val_recall: 0.2329 - val_precision: 0.9598\n",
      "Epoch 10/10\n",
      "4478/4478 [==============================] - 49s 11ms/step - loss: 0.8116 - acc: 0.8108 - f1: 0.3406 - recall: 0.2081 - precision: 0.9404 - val_loss: 0.5333 - val_acc: 0.8948 - val_f1: 0.3762 - val_recall: 0.2340 - val_precision: 0.9622\n"
     ]
    }
   ],
   "source": [
    "model_gru.fit(X_train,Y_train,X_valid,Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de la classe <pad> : 0.7445408734602463\n",
      "Accuracy totale : 0.8864840182648401\n",
      "F1 score totale : 0.13399515354996552\n",
      "Accuracy intent : 0.7077267637178052\n",
      "F1 score intent : 0.04875602700096432\n",
      "Accuracy slot : 0.9023565675648801\n",
      "F1 score slot : 0.1463895821233685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model_gru.predict_no_padding(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893/893 [==============================] - 4s 4ms/step\n",
      "accuracy = 0.8858357752691057 - f1-score = 0.34744741661684775 - recall = 0.21327921955075535 - precision = 0.9514032573609176\n"
     ]
    }
   ],
   "source": [
    "model_gru.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple source: O O O O O O O O O O B-depart_date.day_name B-depart_time.time_relative B-depart_time.time I-depart_time.time O B-fromloc.city_name O O B-toloc.city_name I-toloc.city_name I-toloc.city_name atis_flight_no\n",
      "Exemple prédit: O O O O O O O O O O B-depart_date.day_name B-airline_name B-depart_time.time I-depart_time.time O B-fromloc.city_name O O B-toloc.city_name I-toloc.city_name I-toloc.city_name atis_flight\n"
     ]
    }
   ],
   "source": [
    "idx_test = 500\n",
    "ex = [corpus.dictionary.idx2tag[x] for x in corpus.test.padded_tags[idx_test] if corpus.dictionary.idx2tag[x] !='<pad>']\n",
    "ind = len(ex)\n",
    "pred = [x for x in model_gru.predict(X_test)[idx_test]]\n",
    "print(\"Exemple source:\", ' '.join(ex))\n",
    "print(\"Exemple prédit:\",' '.join(pred[48-ind:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BidirectionalLSTMModel(SlotFilingModel):\n",
    "    \n",
    "    def __init__(self, vocab_size, tag_vocab_size, max_length_sequence, embedding_size,idx2tags,model_path, batch_size= 32, nb_epochs=10, early_stop=True):\n",
    "        super().__init__(vocab_size, tag_vocab_size, max_length_sequence, embedding_size,idx2tags,model_path, batch_size= 32, nb_epochs=10, early_stop=True)\n",
    "        \n",
    "    def model(self,vocab_size,tag_vocab_size,max_length_sequence,embedding_size):\n",
    "        X_input = Input(shape=(max_length_sequence,), dtype='int32')\n",
    "        X = Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_length_sequence, mask_zero = True)(X_input)\n",
    "        A = LSTM(100, return_sequences=True, init='glorot_uniform', activation='relu')(X)\n",
    "        B = LSTM(100, return_sequences=True, init='glorot_uniform', activation='relu', go_backwards=True)(X)\n",
    "        res = concatenate([A, B])\n",
    "        output = TimeDistributed(Dense(tag_vocab_size, activation = \"softmax\"))(res) # time distributed  (sigmoid)\n",
    "        model = Model(inputs = X_input, outputs = output)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(100, return_sequences=True, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(100, return_sequences=True, activation=\"relu\", go_backwards=True, kernel_initializer=\"glorot_uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_60 (InputLayer)           (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_60 (Embedding)        (None, 48, 50)       43550       input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  (None, 48, 100)      60400       embedding_60[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                  (None, 48, 100)      60400       embedding_60[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 48, 200)      0           lstm_15[0][0]                    \n",
      "                                                                 lstm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_53 (TimeDistri (None, 48, 143)      28743       concatenate_52[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 193,093\n",
      "Trainable params: 193,093\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_blstm = BidirectionalLSTMModel(vocab_size,tag_vocab_size,max_len,embedding_size,corpus.dictionary.idx2tag,\"blstm_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4478 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "4478/4478 [==============================] - 46s 10ms/step - loss: 2.5422 - acc: 0.6109 - f1: 0.1248 - recall: 0.0871 - precision: 0.3108 - val_loss: 1.5932 - val_acc: 0.6518 - val_f1: 0.1858 - val_recall: 0.1469 - val_precision: 0.2537\n",
      "Epoch 2/10\n",
      "4478/4478 [==============================] - 37s 8ms/step - loss: 1.0190 - acc: 0.7787 - f1: 0.2614 - recall: 0.1990 - precision: 0.3914 - val_loss: 0.7704 - val_acc: 0.8273 - val_f1: 0.3305 - val_recall: 0.2158 - val_precision: 0.7108\n",
      "Epoch 3/10\n",
      "4478/4478 [==============================] - 46s 10ms/step - loss: 0.5632 - acc: 0.8669 - f1: 0.3612 - recall: 0.2266 - precision: 0.9023 - val_loss: 0.5197 - val_acc: 0.8758 - val_f1: 0.3720 - val_recall: 0.2310 - val_precision: 0.9578\n",
      "Epoch 4/10\n",
      "4478/4478 [==============================] - 35s 8ms/step - loss: 0.3729 - acc: 0.9132 - f1: 0.3852 - recall: 0.2406 - precision: 0.9692 - val_loss: 0.3780 - val_acc: 0.9171 - val_f1: 0.3896 - val_recall: 0.2438 - val_precision: 0.9719\n",
      "Epoch 5/10\n",
      "4478/4478 [==============================] - 34s 8ms/step - loss: 0.2613 - acc: 0.9383 - f1: 0.4001 - recall: 0.2520 - precision: 0.9741 - val_loss: 0.2975 - val_acc: 0.9304 - val_f1: 0.4005 - val_recall: 0.2528 - val_precision: 0.9656\n",
      "Epoch 6/10\n",
      "4478/4478 [==============================] - 36s 8ms/step - loss: 0.2031 - acc: 0.9526 - f1: 0.4075 - recall: 0.2576 - precision: 0.9765 - val_loss: 0.2502 - val_acc: 0.9421 - val_f1: 0.4070 - val_recall: 0.2579 - val_precision: 0.9679\n",
      "Epoch 7/10\n",
      "4478/4478 [==============================] - 42s 9ms/step - loss: 0.1579 - acc: 0.9625 - f1: 0.4134 - recall: 0.2622 - precision: 0.9799 - val_loss: 0.2080 - val_acc: 0.9527 - val_f1: 0.4128 - val_recall: 0.2621 - val_precision: 0.9733\n",
      "Epoch 8/10\n",
      "4478/4478 [==============================] - 42s 9ms/step - loss: 0.1283 - acc: 0.9690 - f1: 0.4169 - recall: 0.2649 - precision: 0.9815 - val_loss: 0.1900 - val_acc: 0.9563 - val_f1: 0.4144 - val_recall: 0.2635 - val_precision: 0.9716\n",
      "Epoch 9/10\n",
      "4478/4478 [==============================] - 34s 8ms/step - loss: 0.1029 - acc: 0.9748 - f1: 0.4190 - recall: 0.2672 - precision: 0.9736 - val_loss: 0.1673 - val_acc: 0.9614 - val_f1: 0.4153 - val_recall: 0.2657 - val_precision: 0.9530\n",
      "Epoch 10/10\n",
      "4478/4478 [==============================] - 34s 8ms/step - loss: 0.0878 - acc: 0.9787 - f1: 0.4199 - recall: 0.2688 - precision: 0.9621 - val_loss: 0.1533 - val_acc: 0.9653 - val_f1: 0.4165 - val_recall: 0.2671 - val_precision: 0.9483\n"
     ]
    }
   ],
   "source": [
    "model_blstm.fit(X_train,Y_train,X_valid,Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de la classe <pad> : 0.7445408734602463\n",
      "Pourcentage de la classe O : 0.14916946621873833\n",
      "Accuracy totale : 0.9541552511415525\n",
      "F1 score totale : 0.9470752686674803\n",
      "Accuracy intent : 0.8499440089585666\n",
      "F1 score intent : 0.8144014806131975\n",
      "Accuracy slot : 0.9634085711444765\n",
      "F1 score slot : 0.9588558884082055\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model_blstm.predict_no_padding(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893/893 [==============================] - 2s 3ms/step\n",
      "accuracy = 0.9541042330283734 - f1-score = 0.38363249241171066 - recall = 0.24106476742102612 - precision = 0.9556385688525432\n"
     ]
    }
   ],
   "source": [
    "model_blstm.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "Exemple source: O O O O O O O O O O B-depart_date.day_name B-depart_time.time_relative B-depart_time.time I-depart_time.time O B-fromloc.city_name O O B-toloc.city_name I-toloc.city_name I-toloc.city_name atis_flight_no\n",
      "Exemple prédit: O O O O O O O O O O B-depart_date.day_name B-depart_time.time_relative B-depart_time.time I-depart_time.time O B-fromloc.city_name O O B-toloc.city_name I-toloc.city_name I-toloc.city_name atis_flight\n"
     ]
    }
   ],
   "source": [
    "idx_test = 500\n",
    "ex = [corpus.dictionary.idx2tag[x] for x in corpus.test.padded_tags[idx_test] if corpus.dictionary.idx2tag[x] !='<pad>']\n",
    "ind = len(ex)\n",
    "pred = [x for x in model_blstm.predict(X_test)[idx_test]]\n",
    "print(\"Exemple source:\", ' '.join(ex))\n",
    "print(\"Exemple prédit:\",' '.join(pred[48-ind:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence to Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeqToSeqModel(SlotFilingModel):\n",
    "    \n",
    "    def __init__(self, vocab_size, tag_vocab_size, max_length_sequence, embedding_size,idx2tags,model_path, batch_size= 32, nb_epochs=20, early_stop=True):\n",
    "        super().__init__(vocab_size, tag_vocab_size, max_length_sequence, embedding_size,idx2tags,model_path, batch_size= 32, nb_epochs=25, early_stop=True)\n",
    "        \n",
    "    def model(self,vocab_size,tag_vocab_size,max_length_sequence,embedding_size):\n",
    "        X_input = Input(shape=(max_length_sequence,), dtype='int32')\n",
    "        X = Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_length_sequence, mask_zero = True)(X_input)\n",
    "        forward = GRU(150,  return_sequences=False, init='glorot_uniform', activation='relu')(X)\n",
    "        backward = GRU(150, return_sequences=False, init='glorot_uniform', activation='relu', go_backwards=True)(X)                                 # dropout (use 0.8)\n",
    "        forward_target = GRU(150, return_sequences=True, init='glorot_uniform', activation='relu')(X)\n",
    "        backward_target = GRU(150, return_sequences=True, init='glorot_uniform', activation='relu', go_backwards=True)(X)\n",
    "        encoder = concatenate([forward, backward])\n",
    "        target = concatenate([forward_target, backward_target])\n",
    "        encoder = RepeatVector(max_length_sequence)(encoder)\n",
    "        tagger = concatenate([encoder, target])\n",
    "        output = TimeDistributed(Dense(tag_vocab_size, activation = \"softmax\"))(tagger) # time distributed  (softmax)\n",
    "        model = Model(inputs = X_input, outputs = output)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(150, return_sequences=False, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(150, return_sequences=False, activation=\"relu\", go_backwards=True, kernel_initializer=\"glorot_uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(150, return_sequences=True, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(150, return_sequences=True, activation=\"relu\", go_backwards=True, kernel_initializer=\"glorot_uniform\")`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_52 (InputLayer)           (None, 47)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_52 (Embedding)        (None, 47, 50)       43500       input_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_86 (GRU)                    (None, 150)          90450       embedding_52[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_87 (GRU)                    (None, 150)          90450       embedding_52[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 300)          0           gru_86[0][0]                     \n",
      "                                                                 gru_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru_88 (GRU)                    (None, 47, 150)      90450       embedding_52[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_89 (GRU)                    (None, 47, 150)      90450       embedding_52[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_14 (RepeatVector) (None, 47, 300)      0           concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 47, 300)      0           gru_88[0][0]                     \n",
      "                                                                 gru_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 47, 600)      0           repeat_vector_14[0][0]           \n",
      "                                                                 concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_49 (TimeDistri (None, 47, 122)      73322       concatenate_41[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 478,622\n",
      "Trainable params: 478,622\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_seq2seq = SeqToSeqModel(vocab_size,tag_vocab_size,max_len,embedding_size,corpus.dictionary.idx2tag,\"seq2seq_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4478 samples, validate on 500 samples\n",
      "Epoch 1/25\n",
      "4478/4478 [==============================] - 61s 14ms/step - loss: 0.1712 - acc: 0.9587 - f1: 0.4074 - recall: 0.2606 - precision: 0.9368 - val_loss: 0.1965 - val_acc: 0.9575 - val_f1: 0.4031 - val_recall: 0.2625 - val_precision: 0.8761\n",
      "Epoch 2/25\n",
      "4478/4478 [==============================] - 60s 13ms/step - loss: 0.1235 - acc: 0.9695 - f1: 0.4008 - recall: 0.2649 - precision: 0.8312 - val_loss: 0.1665 - val_acc: 0.9635 - val_f1: 0.4056 - val_recall: 0.2650 - val_precision: 0.8715\n",
      "Epoch 3/25\n",
      "4478/4478 [==============================] - 60s 13ms/step - loss: 0.0949 - acc: 0.9773 - f1: 0.3840 - recall: 0.2678 - precision: 0.6916 - val_loss: 0.1439 - val_acc: 0.9687 - val_f1: 0.3952 - val_recall: 0.2668 - val_precision: 0.7725\n",
      "Epoch 4/25\n",
      "4478/4478 [==============================] - 60s 13ms/step - loss: 0.0746 - acc: 0.9816 - f1: 0.3767 - recall: 0.2698 - precision: 0.6350 - val_loss: 0.1546 - val_acc: 0.9667 - val_f1: 0.3812 - val_recall: 0.2673 - val_precision: 0.6752\n",
      "Epoch 5/25\n",
      "4478/4478 [==============================] - 61s 14ms/step - loss: 0.0619 - acc: 0.9851 - f1: 0.3703 - recall: 0.2709 - precision: 0.5913 - val_loss: 0.1217 - val_acc: 0.9721 - val_f1: 0.3567 - val_recall: 0.2700 - val_precision: 0.5309\n",
      "Epoch 6/25\n",
      "4478/4478 [==============================] - 63s 14ms/step - loss: 0.0487 - acc: 0.9880 - f1: 0.3506 - recall: 0.2722 - precision: 0.4976 - val_loss: 0.1190 - val_acc: 0.9747 - val_f1: 0.3410 - val_recall: 0.2708 - val_precision: 0.4663\n",
      "Epoch 7/25\n",
      "4478/4478 [==============================] - 61s 14ms/step - loss: 0.0404 - acc: 0.9902 - f1: 0.3395 - recall: 0.2731 - precision: 0.4523 - val_loss: 0.1200 - val_acc: 0.9761 - val_f1: 0.3307 - val_recall: 0.2713 - val_precision: 0.4259\n",
      "Epoch 8/25\n",
      "4478/4478 [==============================] - 61s 14ms/step - loss: 0.0346 - acc: 0.9915 - f1: 0.3460 - recall: 0.2736 - precision: 0.4755 - val_loss: 0.1157 - val_acc: 0.9753 - val_f1: 0.3570 - val_recall: 0.2712 - val_precision: 0.5274\n",
      "Epoch 9/25\n",
      "4478/4478 [==============================] - 61s 14ms/step - loss: 0.0285 - acc: 0.9925 - f1: 0.3391 - recall: 0.2741 - precision: 0.4491 - val_loss: 0.1115 - val_acc: 0.9760 - val_f1: 0.3490 - val_recall: 0.2716 - val_precision: 0.4908\n",
      "Epoch 10/25\n",
      "4478/4478 [==============================] - 62s 14ms/step - loss: 0.0243 - acc: 0.9944 - f1: 0.3392 - recall: 0.2746 - precision: 0.4483 - val_loss: 0.1230 - val_acc: 0.9758 - val_f1: 0.3259 - val_recall: 0.2720 - val_precision: 0.4080\n",
      "Epoch 11/25\n",
      "4478/4478 [==============================] - 61s 14ms/step - loss: 0.0211 - acc: 0.9950 - f1: 0.3356 - recall: 0.2749 - precision: 0.4345 - val_loss: 0.1199 - val_acc: 0.9762 - val_f1: 0.3493 - val_recall: 0.2717 - val_precision: 0.4933\n",
      "Epoch 12/25\n",
      "4478/4478 [==============================] - 61s 14ms/step - loss: 0.0199 - acc: 0.9950 - f1: 0.3392 - recall: 0.2749 - precision: 0.4473 - val_loss: 0.1197 - val_acc: 0.9764 - val_f1: 0.3411 - val_recall: 0.2722 - val_precision: 0.4602\n",
      "Epoch 13/25\n",
      "4478/4478 [==============================] - 62s 14ms/step - loss: 0.0172 - acc: 0.9962 - f1: 0.3360 - recall: 0.2753 - precision: 0.4345 - val_loss: 0.1177 - val_acc: 0.9778 - val_f1: 0.3520 - val_recall: 0.2722 - val_precision: 0.5033\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_seq2seq.fit(X_train,Y_train,X_valid,Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10057 893\n",
      "Pourcentage de la classe <pad> : 0.7445408734602463\n",
      "Accuracy totale : 0.9719634703196347\n",
      "F1 score totale : 0.9697677950258212\n",
      "Accuracy intent : 0.9417693169092946\n",
      "F1 score intent : 0.9397222699134687\n",
      "Accuracy slot : 0.9746445262006562\n",
      "F1 score slot : 0.9724820916304111\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model_seq2seq.predict_no_padding(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893/893 [==============================] - 5s 6ms/step\n",
      "accuracy = 0.9722477341152118 - f1-score = 0.3164574613029185 - recall = 0.24750372473763727 - precision = 0.45234844966271154\n"
     ]
    }
   ],
   "source": [
    "model_seq2seq.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple source: O O O O O O O O O O B-depart_date.day_name B-depart_time.time_relative B-depart_time.time I-depart_time.time O B-fromloc.city_name O O B-toloc.city_name I-toloc.city_name I-toloc.city_name atis_flight_no\n",
      "Exemple prédit: O O O O O O O O O O B-depart_date.day_name B-depart_time.time_relative B-depart_time.time I-depart_time.time O B-fromloc.city_name O O B-toloc.city_name I-toloc.city_name I-toloc.city_name atis_flight_time\n"
     ]
    }
   ],
   "source": [
    "idx_test = 500\n",
    "ex = [corpus.dictionary.idx2tag[x] for x in corpus.test.padded_tags[idx_test] if corpus.dictionary.idx2tag[x] !='<pad>']\n",
    "ind = len(ex)\n",
    "pred = [x for x in model_seq2seq.predict(X_test)[idx_test]]\n",
    "print(\"Exemple source:\", ' '.join(ex))\n",
    "print(\"Exemple prédit:\",' '.join(pred[48-ind:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv1 Encoder Sequence to Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvEncoderSeq2SeqModel(SlotFilingModel):\n",
    "    \n",
    "    def __init__(self, vocab_size, tag_vocab_size, max_length_sequence, embedding_size,idx2tags,model_path, batch_size= 32, nb_epochs=10, early_stop=True):\n",
    "        super().__init__(vocab_size, tag_vocab_size, max_length_sequence, embedding_size,idx2tags,model_path, batch_size= 32, nb_epochs=10, early_stop=True)\n",
    "        \n",
    "    def model(self,vocab_size,tag_vocab_size,max_length_sequence,embedding_size):\n",
    "        X_input = Input(shape=(max_length_sequence,), dtype='int32')\n",
    "        X = Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_length_sequence)(X_input)\n",
    "        X = Convolution1D(50, 3, border_mode='same', input_shape=(48,50))(X)\n",
    "        forward = GRU(150,  return_sequences=False, init='glorot_uniform', activation='relu')(X)\n",
    "        backward = GRU(150, return_sequences=False, init='glorot_uniform', activation='relu', go_backwards=True)(X)                                 # dropout (use 0.8)\n",
    "        forward_target = GRU(150, return_sequences=True, init='glorot_uniform', activation='relu')(X)\n",
    "        backward_target = GRU(150, return_sequences=True, init='glorot_uniform', activation='relu', go_backwards=True)(X)\n",
    "        encoder = concatenate([forward, backward])\n",
    "        target = concatenate([forward_target, backward_target])\n",
    "        encoder = RepeatVector(max_length_sequence)(encoder)\n",
    "        tagger = concatenate([encoder, target])\n",
    "        output = TimeDistributed(Dense(tag_vocab_size, activation = \"softmax\"))(tagger) # time distributed  (sigmoid)\n",
    "        model = Model(inputs = X_input, outputs = output)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(50, 3, input_shape=(48, 50), padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(150, return_sequences=False, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(150, return_sequences=False, activation=\"relu\", go_backwards=True, kernel_initializer=\"glorot_uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(150, return_sequences=True, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  if sys.path[0] == '':\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(150, return_sequences=True, activation=\"relu\", go_backwards=True, kernel_initializer=\"glorot_uniform\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_27 (InputLayer)           (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 48, 50)       43550       input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 48, 50)       7550        embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_36 (GRU)                    (None, 150)          90450       conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_37 (GRU)                    (None, 150)          90450       conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 300)          0           gru_36[0][0]                     \n",
      "                                                                 gru_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru_38 (GRU)                    (None, 48, 150)      90450       conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_39 (GRU)                    (None, 48, 150)      90450       conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_5 (RepeatVector)  (None, 48, 300)      0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 48, 300)      0           gru_38[0][0]                     \n",
      "                                                                 gru_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 48, 600)      0           repeat_vector_5[0][0]            \n",
      "                                                                 concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_24 (TimeDistri (None, 48, 143)      85943       concatenate_18[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 498,843\n",
      "Trainable params: 498,843\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_convSeq2Seq = ConvEncoderSeq2SeqModel(vocab_size,tag_vocab_size,max_len,embedding_size,corpus.dictionary.idx2tag,\"convSeq2Seq_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4478 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "4478/4478 [==============================] - 63s 14ms/step - loss: 1.1075 - acc: 0.8322 - f1: 0.7483 - recall: 0.7116 - precision: 0.7902 - val_loss: 0.4785 - val_acc: 0.8927 - val_f1: 0.9057 - val_recall: 0.8668 - val_precision: 0.9483\n",
      "Epoch 2/10\n",
      "4478/4478 [==============================] - 55s 12ms/step - loss: 0.3621 - acc: 0.9151 - f1: 0.9230 - recall: 0.8857 - precision: 0.9640 - val_loss: 0.2618 - val_acc: 0.9399 - val_f1: 0.9466 - val_recall: 0.9182 - val_precision: 0.9769\n",
      "Epoch 3/10\n",
      "4478/4478 [==============================] - 53s 12ms/step - loss: 0.1751 - acc: 0.9580 - f1: 0.9648 - recall: 0.9436 - precision: 0.9870 - val_loss: 0.1421 - val_acc: 0.9655 - val_f1: 0.9701 - val_recall: 0.9539 - val_precision: 0.9869\n",
      "Epoch 4/10\n",
      "4478/4478 [==============================] - 63s 14ms/step - loss: 0.0964 - acc: 0.9764 - f1: 0.9791 - recall: 0.9679 - precision: 0.9905 - val_loss: 0.0956 - val_acc: 0.9774 - val_f1: 0.9801 - val_recall: 0.9713 - val_precision: 0.9891\n",
      "Epoch 5/10\n",
      "4478/4478 [==============================] - 57s 13ms/step - loss: 0.0683 - acc: 0.9826 - f1: 0.9841 - recall: 0.9769 - precision: 0.9915 - val_loss: 0.0829 - val_acc: 0.9807 - val_f1: 0.9819 - val_recall: 0.9766 - val_precision: 0.9873\n",
      "Epoch 6/10\n",
      "4478/4478 [==============================] - 54s 12ms/step - loss: 0.0508 - acc: 0.9869 - f1: 0.9876 - recall: 0.9824 - precision: 0.9929 - val_loss: 0.0635 - val_acc: 0.9839 - val_f1: 0.9860 - val_recall: 0.9807 - val_precision: 0.9913\n",
      "Epoch 7/10\n",
      "4478/4478 [==============================] - 59s 13ms/step - loss: 0.0405 - acc: 0.9892 - f1: 0.9900 - recall: 0.9859 - precision: 0.9942 - val_loss: 0.0594 - val_acc: 0.9861 - val_f1: 0.9867 - val_recall: 0.9814 - val_precision: 0.9920\n",
      "Epoch 8/10\n",
      "4478/4478 [==============================] - 57s 13ms/step - loss: 0.0329 - acc: 0.9914 - f1: 0.9919 - recall: 0.9887 - precision: 0.9951 - val_loss: 0.0522 - val_acc: 0.9883 - val_f1: 0.9889 - val_recall: 0.9849 - val_precision: 0.9928\n",
      "Epoch 9/10\n",
      "4478/4478 [==============================] - 60s 14ms/step - loss: 0.0277 - acc: 0.9927 - f1: 0.9931 - recall: 0.9905 - precision: 0.9958 - val_loss: 0.0476 - val_acc: 0.9895 - val_f1: 0.9903 - val_recall: 0.9869 - val_precision: 0.9937\n",
      "Epoch 10/10\n",
      "4478/4478 [==============================] - 57s 13ms/step - loss: 0.0228 - acc: 0.9940 - f1: 0.9943 - recall: 0.9923 - precision: 0.9964 - val_loss: 0.0483 - val_acc: 0.9892 - val_f1: 0.9901 - val_recall: 0.9875 - val_precision: 0.9928\n"
     ]
    }
   ],
   "source": [
    "model_convSeq2Seq.fit(X_train,Y_train,X_valid,Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893/893 [==============================] - 5s 6ms/step\n",
      "accuracy = 0.9864455083716757 - f1-score = 0.987764570907943 - recall = 0.9848357572534183 - precision = 0.9907186399782358\n"
     ]
    }
   ],
   "source": [
    "model_convSeq2Seq.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de la classe <pad> : 0.7445408734602463\n",
      "Accuracy totale : 0.9469406392694064\n",
      "F1 score totale : 0.9428629218268111\n",
      "Accuracy intent : 0.8521836506159015\n",
      "F1 score intent : 0.8236020168865738\n",
      "Accuracy slot : 0.9553544794670379\n",
      "F1 score slot : 0.9541213262807624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model_convSeq2Seq.predict_no_padding(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple source: O O O O O O O O O O B-depart_date.day_name B-depart_time.time_relative B-depart_time.time I-depart_time.time O B-fromloc.city_name O O B-toloc.city_name I-toloc.city_name I-toloc.city_name atis_flight_no\n",
      "Exemple prédit: O O O O O O O O O O B-depart_date.day_name B-depart_time.time_relative B-depart_time.time I-depart_time.time O B-fromloc.city_name O O B-toloc.city_name I-toloc.city_name I-toloc.city_name atis_flight\n"
     ]
    }
   ],
   "source": [
    "idx_test = 500\n",
    "ex = [corpus.dictionary.idx2tag[x] for x in corpus.test.padded_tags[idx_test] if corpus.dictionary.idx2tag[x] !='<pad>']\n",
    "ind = len(ex)\n",
    "pred = [x for x in model_convSeq2Seq.predict(X_test)[idx_test]]\n",
    "print(\"Exemple source:\", ' '.join(ex))\n",
    "print(\"Exemple prédit:\",' '.join(pred[48-ind:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taches séparées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slot Filling detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy import io\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "class Corpus2(object):\n",
    "    \n",
    "    def __init__(self, data_dir='data',embeddings_file=\"glove.6B.50d.txt\", train_file=\"atis-2.train.w-intent.iob\", valid_file=\"atis-2.dev.w-intent.iob\" ,test_file=\"atis.test.w-intent.iob\",):\n",
    "        self.train = SlotDataset()\n",
    "        self.valid = SlotDataset()\n",
    "        self.test = SlotDataset()\n",
    "        \n",
    "        self.dictionary = Dictionary()\n",
    "        #self.embeddings = GolveEmbbedings(os.path.join(data_dir, embeddings_file))\n",
    "        self.load_train(os.path.join(data_dir, train_file))\n",
    "        self.load_valid(os.path.join(data_dir, valid_file))\n",
    "        self.load_test(os.path.join(data_dir, test_file))\n",
    "        \n",
    "    def load_train(self, path):\n",
    "        for line in open(path, 'r'):\n",
    "            words=line.split('\\t')[0].strip().split()\n",
    "            tags=line.split('\\t')[1].strip().split()\n",
    "            temp_utt = list()\n",
    "            temp_tags = list()\n",
    "            for i in range(len(words[0:-1])):\n",
    "                id_word = self.dictionary.add_word(words[i])\n",
    "                id_tag  = self.dictionary.add_tag(tags[i])\n",
    "                temp_utt.append(id_word)\n",
    "                temp_tags.append(id_tag)\n",
    "            self.train.add_utterance(np.array(temp_utt))\n",
    "            self.train.add_slots(np.array(temp_tags))\n",
    "    \n",
    "    def load_valid(self, path):\n",
    "        for line in open(path, 'r'):\n",
    "            words=line.split('\\t')[0].strip().split()\n",
    "            tags =line.split('\\t')[1].strip().split()\n",
    "            temp_utt = list()\n",
    "            temp_tags = list()\n",
    "            for i in range(len(words[0:-1])):\n",
    "                if words[i] not in self.dictionary.word2idx :\n",
    "                    temp_utt.append(1) \n",
    "                else:\n",
    "                    temp_utt.append(self.dictionary.word2idx[words[i]])\n",
    "                if tags[i] not in self.dictionary.tag2idx :\n",
    "                    temp_tags.append(1) \n",
    "                else:\n",
    "                    temp_tags.append(self.dictionary.tag2idx[tags[i]])\n",
    "            self.valid.add_utterance(np.array(temp_utt))\n",
    "            self.valid.add_slots(np.array(temp_tags))\n",
    "            \n",
    "    def load_test(self, path):\n",
    "        for line in open(path, 'r'):\n",
    "            words=line.split('\\t')[0].strip().split()\n",
    "            tags =line.split('\\t')[1].strip().split()\n",
    "            temp_utt = list()\n",
    "            temp_tags = list()\n",
    "            for i in range(len(words[0:-1])):\n",
    "                if words[i] not in self.dictionary.word2idx :\n",
    "                    temp_utt.append(1) \n",
    "                else:\n",
    "                    temp_utt.append(self.dictionary.word2idx[words[i]])\n",
    "                if tags[i] not in self.dictionary.tag2idx :\n",
    "                    temp_tags.append(1) \n",
    "                else:\n",
    "                    temp_tags.append(self.dictionary.tag2idx[tags[i]])\n",
    "            self.test.add_utterance(np.array(temp_utt))\n",
    "            self.test.add_slots(np.array(temp_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus2 = Corpus2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  3,  2,  4, 18,  2,  2,  2,  2,  2, 13, 19], dtype=int32)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len  = max([ len(x) for x in  corpus2.train.utterances])\n",
    "vocab_size = len(corpus2.dictionary.word2idx)\n",
    "tag_vocab_size = len(corpus2.dictionary.tag2idx)\n",
    "embedding_size = 50\n",
    "corpus2.train.pad_utts(time_length=max_len)\n",
    "corpus2.train.pad_tags(time_length=max_len)\n",
    "corpus2.valid.pad_utts(time_length=max_len)\n",
    "corpus2.valid.pad_tags(time_length=max_len)\n",
    "corpus2.test.pad_utts(time_length=max_len)\n",
    "corpus2.test.pad_tags(time_length=max_len)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = corpus2.train.padded_utterances\n",
    "X_valid = corpus2.valid.padded_utterances\n",
    "X_test = corpus2.test.padded_utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (4478, 47)\n",
      "Dev shape (500, 47)\n",
      "Test shape (893, 47)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape \" + str(X_train.shape))\n",
    "print(\"Dev shape \" + str(X_valid.shape))\n",
    "print(\"Test shape \" + str(X_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = corpus2.train.get_one_hot_tags(tag_vocab_size)\n",
    "Y_valid = corpus2.valid.get_one_hot_tags(tag_vocab_size)\n",
    "Y_test = corpus2.test.get_one_hot_tags(tag_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label shape (4478, 47, 122)\n",
      "Dev label shape (500, 47, 122)\n",
      "Test label shape (893, 47, 122)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train label shape \" + str(Y_train.shape))\n",
    "print(\"Dev label shape \" + str(Y_valid.shape))\n",
    "print(\"Test label shape \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(150, return_sequences=False, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(150, return_sequences=False, activation=\"relu\", go_backwards=True, kernel_initializer=\"glorot_uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(150, return_sequences=True, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(150, return_sequences=True, activation=\"relu\", go_backwards=True, kernel_initializer=\"glorot_uniform\")`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_55 (InputLayer)           (None, 47)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_55 (Embedding)        (None, 47, 50)       43500       input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_95 (GRU)                    (None, 150)          90450       embedding_55[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_96 (GRU)                    (None, 150)          90450       embedding_55[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 300)          0           gru_95[0][0]                     \n",
      "                                                                 gru_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru_97 (GRU)                    (None, 47, 150)      90450       embedding_55[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_98 (GRU)                    (None, 47, 150)      90450       embedding_55[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_16 (RepeatVector) (None, 47, 300)      0           concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 47, 300)      0           gru_97[0][0]                     \n",
      "                                                                 gru_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 47, 600)      0           repeat_vector_16[0][0]           \n",
      "                                                                 concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_52 (TimeDistri (None, 47, 122)      73322       concatenate_47[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 478,622\n",
      "Trainable params: 478,622\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_seq2seq = SeqToSeqModel(vocab_size,tag_vocab_size,max_len,embedding_size,corpus2.dictionary.idx2tag,\"sf_seq2seq_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4478 samples, validate on 500 samples\n",
      "Epoch 1/25\n",
      "4478/4478 [==============================] - 76s 17ms/step - loss: 1.9249 - acc: 0.6839 - f1: 0.1769 - recall: 0.1338 - precision: 0.2990 - val_loss: 0.9399 - val_acc: 0.8040 - val_f1: 0.3157 - val_recall: 0.2023 - val_precision: 0.7282\n",
      "Epoch 2/25\n",
      "4478/4478 [==============================] - 62s 14ms/step - loss: 0.6355 - acc: 0.8535 - f1: 0.3477 - recall: 0.2123 - precision: 0.9667 - val_loss: 0.5230 - val_acc: 0.8779 - val_f1: 0.3551 - val_recall: 0.2170 - val_precision: 0.9807\n",
      "Epoch 3/25\n",
      "4478/4478 [==============================] - 61s 14ms/step - loss: 0.3710 - acc: 0.9115 - f1: 0.3687 - recall: 0.2272 - precision: 0.9804 - val_loss: 0.3279 - val_acc: 0.9260 - val_f1: 0.3789 - val_recall: 0.2352 - val_precision: 0.9779\n",
      "Epoch 4/25\n",
      "4478/4478 [==============================] - 60s 13ms/step - loss: 0.2242 - acc: 0.9462 - f1: 0.3843 - recall: 0.2411 - precision: 0.9515 - val_loss: 0.2369 - val_acc: 0.9452 - val_f1: 0.3888 - val_recall: 0.2434 - val_precision: 0.9695\n",
      "Epoch 5/25\n",
      "4478/4478 [==============================] - 63s 14ms/step - loss: 0.1545 - acc: 0.9625 - f1: 0.3865 - recall: 0.2472 - precision: 0.8963 - val_loss: 0.1844 - val_acc: 0.9593 - val_f1: 0.3891 - val_recall: 0.2485 - val_precision: 0.9024\n",
      "Epoch 6/25\n",
      "4478/4478 [==============================] - 60s 13ms/step - loss: 0.1150 - acc: 0.9721 - f1: 0.3859 - recall: 0.2507 - precision: 0.8488 - val_loss: 0.1588 - val_acc: 0.9657 - val_f1: 0.3704 - val_recall: 0.2515 - val_precision: 0.7111\n",
      "Epoch 7/25\n",
      "4478/4478 [==============================] - 63s 14ms/step - loss: 0.0886 - acc: 0.9790 - f1: 0.3846 - recall: 0.2533 - precision: 0.8085 - val_loss: 0.1403 - val_acc: 0.9692 - val_f1: 0.3968 - val_recall: 0.2529 - val_precision: 0.9242\n",
      "Epoch 8/25\n",
      "4478/4478 [==============================] - 62s 14ms/step - loss: 0.0680 - acc: 0.9837 - f1: 0.3837 - recall: 0.2553 - precision: 0.7839 - val_loss: 0.1277 - val_acc: 0.9730 - val_f1: 0.3673 - val_recall: 0.2551 - val_precision: 0.6639\n",
      "Epoch 9/25\n",
      "4478/4478 [==============================] - 60s 14ms/step - loss: 0.0524 - acc: 0.9869 - f1: 0.3757 - recall: 0.2566 - precision: 0.7117 - val_loss: 0.1195 - val_acc: 0.9749 - val_f1: 0.3821 - val_recall: 0.2561 - val_precision: 0.7642\n",
      "Epoch 10/25\n",
      "4478/4478 [==============================] - 65s 15ms/step - loss: 0.0430 - acc: 0.9889 - f1: 0.3705 - recall: 0.2573 - precision: 0.6710 - val_loss: 0.1105 - val_acc: 0.9770 - val_f1: 0.3726 - val_recall: 0.2566 - val_precision: 0.6882\n",
      "Epoch 11/25\n",
      "4478/4478 [==============================] - 62s 14ms/step - loss: 0.0348 - acc: 0.9909 - f1: 0.3677 - recall: 0.2581 - precision: 0.6493 - val_loss: 0.1024 - val_acc: 0.9792 - val_f1: 0.3457 - val_recall: 0.2576 - val_precision: 0.5302\n",
      "Epoch 12/25\n",
      "4478/4478 [==============================] - 62s 14ms/step - loss: 0.0282 - acc: 0.9922 - f1: 0.3576 - recall: 0.2586 - precision: 0.5880 - val_loss: 0.1106 - val_acc: 0.9758 - val_f1: 0.3593 - val_recall: 0.2567 - val_precision: 0.6058\n",
      "Epoch 13/25\n",
      "4478/4478 [==============================] - 60s 13ms/step - loss: 0.0238 - acc: 0.9937 - f1: 0.3463 - recall: 0.2591 - precision: 0.5286 - val_loss: 0.0999 - val_acc: 0.9804 - val_f1: 0.3596 - val_recall: 0.2581 - val_precision: 0.5996\n",
      "Epoch 14/25\n",
      "4478/4478 [==============================] - 60s 13ms/step - loss: 0.0204 - acc: 0.9948 - f1: 0.3420 - recall: 0.2595 - precision: 0.5096 - val_loss: 0.1122 - val_acc: 0.9763 - val_f1: 0.3420 - val_recall: 0.2569 - val_precision: 0.5164\n",
      "Epoch 15/25\n",
      "4478/4478 [==============================] - 60s 13ms/step - loss: 0.0183 - acc: 0.9954 - f1: 0.3449 - recall: 0.2597 - precision: 0.5197 - val_loss: 0.1025 - val_acc: 0.9797 - val_f1: 0.3418 - val_recall: 0.2579 - val_precision: 0.5112\n",
      "Epoch 16/25\n",
      "4478/4478 [==============================] - 62s 14ms/step - loss: 0.0135 - acc: 0.9969 - f1: 0.3394 - recall: 0.2602 - precision: 0.4926 - val_loss: 0.1050 - val_acc: 0.9776 - val_f1: 0.3283 - val_recall: 0.2577 - val_precision: 0.4544\n",
      "Epoch 17/25\n",
      "4478/4478 [==============================] - 62s 14ms/step - loss: 0.0120 - acc: 0.9973 - f1: 0.3318 - recall: 0.2603 - precision: 0.4609 - val_loss: 0.1104 - val_acc: 0.9791 - val_f1: 0.3341 - val_recall: 0.2580 - val_precision: 0.4763\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_seq2seq.fit(X_train,Y_train,X_valid,Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de la classe <pad> : 0.7603821686402517\n",
      "Pourcentage de la classe O : 0.15234328464892427\n",
      "Accuracy totale : 0.9680819329820026\n",
      "F1 score totale : 0.9649034288098005\n",
      "Accuracy intent : 1.0\n",
      "F1 score intent : 1.0\n",
      "Accuracy slot : 0.9679928208196231\n",
      "F1 score slot : 0.964805590085802\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model_seq2seq.predict_no_padding(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893/893 [==============================] - 4s 5ms/step\n",
      "accuracy = 0.9687159047415115 - f1-score = 0.30658431806729863 - recall = 0.23158847871846608 - precision = 0.45780669821870557\n"
     ]
    }
   ],
   "source": [
    "model_seq2seq.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple source: O O O O O O O O O O B-depart_date.day_name B-depart_time.time_relative B-depart_time.time I-depart_time.time O B-fromloc.city_name O O B-toloc.city_name I-toloc.city_name I-toloc.city_name\n",
      "Exemple prédit: O O O O O O O O O B-airline_name B-depart_time.period_of_day B-depart_date.day_name B-airline_code O B-fromloc.city_name O O B-toloc.city_name I-arrive_time.time I-arrive_time.time\n"
     ]
    }
   ],
   "source": [
    "idx_test = 500\n",
    "ex = [corpus2.dictionary.idx2tag[x] for x in corpus2.test.padded_tags[idx_test] if corpus2.dictionary.idx2tag[x] !='<pad>']\n",
    "ind = len(ex)\n",
    "pred = [x for x in model_seq2seq.predict(X_test)[idx_test]]\n",
    "print(\"Exemple source:\", ' '.join(ex))\n",
    "print(\"Exemple prédit:\",' '.join(pred[48-ind:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy import io\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "class Corpus3(object):\n",
    "    \n",
    "    def __init__(self, data_dir='data',embeddings_file=\"glove.6B.50d.txt\", train_file=\"atis-2.train.w-intent.iob\", valid_file=\"atis-2.dev.w-intent.iob\" ,test_file=\"atis.test.w-intent.iob\",):\n",
    "        self.train = SlotDataset()\n",
    "        self.valid = SlotDataset()\n",
    "        self.test = SlotDataset()\n",
    "        \n",
    "        self.dictionary = Dictionary()\n",
    "        #self.embeddings = GolveEmbbedings(os.path.join(data_dir, embeddings_file))\n",
    "        self.load_train(os.path.join(data_dir, train_file))\n",
    "        self.load_valid(os.path.join(data_dir, valid_file))\n",
    "        self.load_test(os.path.join(data_dir, test_file))\n",
    "        \n",
    "    def load_train(self, path):\n",
    "        for line in open(path, 'r'):\n",
    "            words=line.split('\\t')[0].strip().split()\n",
    "            tags=line.split('\\t')[1].strip().split()\n",
    "            temp_utt = list()\n",
    "            temp_tags = list()\n",
    "            for i in range(len(words[0:-1])):\n",
    "                id_word = self.dictionary.add_word(words[i])\n",
    "                id_tag  = self.dictionary.add_tag(tags[-1])\n",
    "                temp_utt.append(id_word)\n",
    "                temp_tags.append(id_tag)\n",
    "            self.train.add_utterance(np.array(temp_utt))\n",
    "            self.train.add_slots(np.array(temp_tags))\n",
    "    \n",
    "    def load_valid(self, path):\n",
    "        for line in open(path, 'r'):\n",
    "            words=line.split('\\t')[0].strip().split()\n",
    "            tags =line.split('\\t')[1].strip().split()\n",
    "            temp_utt = list()\n",
    "            temp_tags = list()\n",
    "            for i in range(len(words[0:-1])):\n",
    "                if words[i] not in self.dictionary.word2idx :\n",
    "                    temp_utt.append(1) \n",
    "                else:\n",
    "                    temp_utt.append(self.dictionary.word2idx[words[i]])\n",
    "                if tags[-1] not in self.dictionary.tag2idx :\n",
    "                    temp_tags.append(1) \n",
    "                else:\n",
    "                    temp_tags.append(self.dictionary.tag2idx[tags[-1]])\n",
    "            self.valid.add_utterance(np.array(temp_utt))\n",
    "            self.valid.add_slots(np.array(temp_tags))\n",
    "            \n",
    "    def load_test(self, path):\n",
    "        for line in open(path, 'r'):\n",
    "            words=line.split('\\t')[0].strip().split()\n",
    "            tags =line.split('\\t')[1].strip().split()\n",
    "            temp_utt = list()\n",
    "            temp_tags = list()\n",
    "            for i in range(len(words[0:-1])):\n",
    "                if words[i] not in self.dictionary.word2idx :\n",
    "                    temp_utt.append(1) \n",
    "                else:\n",
    "                    temp_utt.append(self.dictionary.word2idx[words[i]])\n",
    "                if tags[-1] not in self.dictionary.tag2idx :\n",
    "                    temp_tags.append(1) \n",
    "                else:\n",
    "                    temp_tags.append(self.dictionary.tag2idx[tags[-1]])\n",
    "            self.test.add_utterance(np.array(temp_utt))\n",
    "            self.test.add_slots(np.array(temp_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BidirectionalLSTMModelID(SlotFilingModel):\n",
    "    \n",
    "    def __init__(self, vocab_size, tag_vocab_size, max_length_sequence, embedding_size,idx2tags,model_path, batch_size= 32, nb_epochs=10, early_stop=True):\n",
    "        super().__init__(vocab_size, tag_vocab_size, max_length_sequence, embedding_size,idx2tags,model_path, batch_size= 32, nb_epochs=10, early_stop=True)\n",
    "        \n",
    "    def model(self,vocab_size,tag_vocab_size,max_length_sequence,embedding_size):\n",
    "        X_input = Input(shape=(max_length_sequence,), dtype='int32')\n",
    "        X = Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_length_sequence, mask_zero = True)(X_input)\n",
    "        A = LSTM(100, return_sequences=False, init='glorot_uniform', activation='relu')(X)\n",
    "        B = LSTM(100, return_sequences=False, init='glorot_uniform', activation='relu', go_backwards=True)(X)\n",
    "        res = concatenate([A, B])\n",
    "        output = Dense(tag_vocab_size, activation = \"softmax\")(res) # time distributed  (sigmoid)\n",
    "        model = Model(inputs = X_input, outputs = output)\n",
    "        return model\n",
    "    \n",
    "    def predict_no_padding(self,X,Y):\n",
    "        if os.path.exists(self.model_path):\n",
    "            self.load(self.model_path)\n",
    "        preds = self.model.predict(X)\n",
    "        res_total = []\n",
    "        pre_total = []\n",
    "        res_intent = []\n",
    "        pre_intent = []\n",
    "        cpt = 0\n",
    "        p=0\n",
    "        for i,a in enumerate(Y):\n",
    "            t = np.argmax(a)\n",
    "            res_intent.append(t)\n",
    "            pre_intent.append(np.argmax(preds[i]))\n",
    "        \n",
    "        print(\"Accuracy intent :\",accuracy_score(res_intent,pre_intent))\n",
    "        print(\"F1 score intent :\",f1_score(res_intent,pre_intent,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus3 = Corpus3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2], dtype=int32)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len  = max([ len(x) for x in  corpus3.train.utterances])\n",
    "vocab_size = len(corpus3.dictionary.word2idx)\n",
    "tag_vocab_size = len(corpus3.dictionary.tag2idx)\n",
    "embedding_size = 50\n",
    "corpus3.train.pad_utts(time_length=max_len)\n",
    "corpus3.train.pad_tags(time_length=max_len)\n",
    "corpus3.valid.pad_utts(time_length=max_len)\n",
    "corpus3.valid.pad_tags(time_length=max_len)\n",
    "corpus3.test.pad_utts(time_length=max_len)\n",
    "corpus3.test.pad_tags(time_length=max_len)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = corpus3.train.padded_utterances\n",
    "X_valid = corpus3.valid.padded_utterances\n",
    "X_test = corpus3.test.padded_utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (4478, 47)\n",
      "Dev shape (500, 47)\n",
      "Test shape (893, 47)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape \" + str(X_train.shape))\n",
    "print(\"Dev shape \" + str(X_valid.shape))\n",
    "print(\"Test shape \" + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = corpus3.train.get_one_hot_tags(tag_vocab_size)\n",
    "Y_valid = corpus3.valid.get_one_hot_tags(tag_vocab_size)\n",
    "Y_test = corpus3.test.get_one_hot_tags(tag_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label shape (4478, 47, 23)\n",
      "Dev label shape (500, 47, 23)\n",
      "Test label shape (893, 47, 23)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train label shape \" + str(Y_train.shape))\n",
    "print(\"Dev label shape \" + str(Y_valid.shape))\n",
    "print(\"Test label shape \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(100, return_sequences=False, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/startup/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(100, return_sequences=False, activation=\"relu\", go_backwards=True, kernel_initializer=\"glorot_uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_59 (InputLayer)           (None, 47)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_59 (Embedding)        (None, 47, 50)       43500       input_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                  (None, 100)          60400       embedding_59[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  (None, 100)          60400       embedding_59[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 200)          0           lstm_13[0][0]                    \n",
      "                                                                 lstm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 23)           4623        concatenate_51[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 168,923\n",
      "Trainable params: 168,923\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_blstm = BidirectionalLSTMModel(vocab_size,tag_vocab_size,max_len,embedding_size,corpus3.dictionary.idx2tag,\"blstm_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4478 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "4478/4478 [==============================] - 33s 7ms/step - loss: 1.4361 - acc: 0.7327 - f1: 0.6030 - recall: 0.5393 - precision: 0.7204 - val_loss: 0.9973 - val_acc: 0.7140 - val_f1: 0.7534 - val_recall: 0.6960 - val_precision: 0.8245\n",
      "Epoch 2/10\n",
      "4478/4478 [==============================] - 25s 6ms/step - loss: 0.8168 - acc: 0.7711 - f1: 0.8010 - recall: 0.7186 - precision: 0.9124 - val_loss: 0.7722 - val_acc: 0.7980 - val_f1: 0.8085 - val_recall: 0.7480 - val_precision: 0.8819\n",
      "Epoch 3/10\n",
      "4478/4478 [==============================] - 24s 5ms/step - loss: 0.5201 - acc: 0.8691 - f1: 0.8838 - recall: 0.8247 - precision: 0.9550 - val_loss: 0.5388 - val_acc: 0.8480 - val_f1: 0.8786 - val_recall: 0.8260 - val_precision: 0.9410\n",
      "Epoch 4/10\n",
      "4478/4478 [==============================] - 25s 6ms/step - loss: 0.4017 - acc: 0.8928 - f1: 0.9091 - recall: 0.8553 - precision: 0.9738 - val_loss: 0.4815 - val_acc: 0.8600 - val_f1: 0.8853 - val_recall: 0.8200 - val_precision: 0.9647\n",
      "Epoch 5/10\n",
      "4478/4478 [==============================] - 27s 6ms/step - loss: 0.3241 - acc: 0.9091 - f1: 0.9253 - recall: 0.8781 - precision: 0.9795 - val_loss: 0.4217 - val_acc: 0.8880 - val_f1: 0.8999 - val_recall: 0.8580 - val_precision: 0.9472\n",
      "Epoch 6/10\n",
      "4478/4478 [==============================] - 24s 5ms/step - loss: 0.2658 - acc: 0.9303 - f1: 0.9347 - recall: 0.8937 - precision: 0.9811 - val_loss: 0.3690 - val_acc: 0.9040 - val_f1: 0.9087 - val_recall: 0.8640 - val_precision: 0.9597\n",
      "Epoch 7/10\n",
      "4478/4478 [==============================] - 25s 6ms/step - loss: 0.2019 - acc: 0.9486 - f1: 0.9522 - recall: 0.9218 - precision: 0.9859 - val_loss: 0.3194 - val_acc: 0.9300 - val_f1: 0.9308 - val_recall: 0.9000 - val_precision: 0.9653\n",
      "Epoch 8/10\n",
      "4478/4478 [==============================] - 24s 5ms/step - loss: 0.1892 - acc: 0.9576 - f1: 0.9614 - recall: 0.9399 - precision: 0.9846 - val_loss: 0.6285 - val_acc: 0.8620 - val_f1: 0.8628 - val_recall: 0.8280 - val_precision: 0.9017\n",
      "Epoch 9/10\n",
      "4478/4478 [==============================] - 24s 5ms/step - loss: 0.1703 - acc: 0.9614 - f1: 0.9641 - recall: 0.9446 - precision: 0.9850 - val_loss: 0.3129 - val_acc: 0.9480 - val_f1: 0.9460 - val_recall: 0.9240 - val_precision: 0.9709\n",
      "Epoch 10/10\n",
      "4478/4478 [==============================] - 26s 6ms/step - loss: 0.1076 - acc: 0.9759 - f1: 0.9760 - recall: 0.9616 - precision: 0.9912 - val_loss: 0.3276 - val_acc: 0.9520 - val_f1: 0.9509 - val_recall: 0.9360 - val_precision: 0.9668\n"
     ]
    }
   ],
   "source": [
    "model_blstm.fit(X_train,Y_train[:,-1:].reshape(-1,23),X_valid,Y_valid[:,-1:].reshape(-1,23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy intent : 0.9137737961926092\n",
      "F1 score intent : 0.9001609567022054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startup/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model_blstm.predict_no_padding(X_test,Y_test[:,-1:].reshape(-1,23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893/893 [==============================] - 2s 2ms/step\n",
      "accuracy = 0.9137737963261022 - f1-score = 0.9188316395675215 - recall = 0.891377379752754 - precision = 0.950968141518408\n"
     ]
    }
   ],
   "source": [
    "model_blstm.evaluate(X_test,Y_test[:,-1:].reshape(-1,23))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
